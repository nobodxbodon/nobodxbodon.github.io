<h2><a href="https://github.com/shiina18/shiina18.github.io/blob/master/_posts/2025-10-17-agent.md">仓库源文</a>，<a href="https://shiina18.github.io/machine%20learning/2025/10/17/agent">站点原文</a></h2>
<p>2025 年大家都忙着搞 agent. 下面分类是随便分的.</p>
&lt;!-- more --&gt;

<p><strong>Tools/Prompts</strong></p>
<ul>
<li><a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/tree/main">System Prompts and Models of AI Tools</a>. 各种 AI 的系统提示词以及 tool schema</li>
<li><a href="https://github.com/anthropics/claude-cookbooks/tree/main/patterns%2Fagents%2Fprompts">Claude Cookbooks</a>. citation 和 research agent 的提示词示范</li>
<li>2025-05. <a href="https://simonwillison.net/2025/May/25/claude-4-system-prompt/">Highlights from the Claude 4 system prompt</a>. 分析提示词</li>
<li>2025-03. <a href="https://www.robertodiasduarte.com.br/en/markdown-vs-xml-em-prompts-para-llms-uma-analise-comparativa/">Markdown vs. XML in LLM Prompts: A Comparative Analysis</a></li>
<li>Claude Docs. <a href="https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/long-context-tips#essential-tips-for-long-context-prompts">Essential tips for long context prompts</a></li>
<li>2025-04. <a href="https://macro.com/app/md/54115a42-3409-4f5b-9120-f144d3ecd23a">How ChatGPT Memory Works</a>. 逆向 memory tool</li>
<li>2025-06. <a href="https://zhuanlan.zhihu.com/p/1922453251657271046">逆向 Gemini 2.5 Pro 搜索功能</a>. Browse 工具是个 sub-agent, 根据提示词从网页中返回相关信息给主 agent.</li>
<li>Anthropic. 2025-03. <a href="https://www.anthropic.com/engineering/claude-think-tool">The "think" tool: Enabling Claude to stop and think in complex tool use situations</a></li>
<li>Anthropic. 2025-09. <a href="https://www.anthropic.com/engineering/writing-tools-for-agents">Writing effective tools for agents — with agents</a></li>
</ul>
<p><strong>Context-Engineering</strong></p>
<ul>
<li>Lance's Blog. 2025-06. <a href="https://rlancemartin.github.io/2025/06/23/context_engineering/">Context Engineering for Agents</a></li>
<li>Drew Breunig. 2025-06. <a href="https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html">How Long Contexts Fail</a></li>
<li>manus. 2025-07. <a href="https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus">Context Engineering for AI Agents: Lessons from Building Manus</a></li>
<li>周星星-知乎. 2025-09. <a href="https://zhuanlan.zhihu.com/p/1953085369328337945">Context Engineering 上下文工程的前世今生</a></li>
<li>2025-10. <a href="https://www.youtube.com/watch?v=6_BcCthVvb8">Context Engineering for AI Agents with LangChain and Manus - YouTube</a>. PMF 之前别训模型<ul>
<li><a href="https://docs.google.com/presentation/d/16aaXLu40GugY-kOpqDU4e-S0hD1FmHcNyF0rRRnb1OU/edit?slide=id.p#slide=id.p">Lance Martin's slides (LangChain)</a></li>
<li><a href="https://drive.google.com/file/d/1QGJ-BrdiTGslS71sYH4OJoidsry3Ps9g/view">Yichao "Peak" Ji's slides (Manus)</a></li>
</ul>
</li>
<li>Anthropic. 2025-10. <a href="https://www.anthropic.com/news/skills">Introducing Claude Skills</a>. 不同于之前的 tools/mcp, skills 可以层级化地提供信息, 提供信息的方式更灵活, LLM 按需加载, 而无需一开始就把所有 desc 都加载到 prompt 中. 上面那篇 manus 里也有提到他们做了类似的按需加载的模式.</li>
</ul>
<p><strong>System</strong></p>
<p>现在趋势是自己不做 index (分块 + 向量化 + 向量数据库), 直接让 LLM grep 或者 web search. 比如 Claude, Cline, manus 都是如此.</p>
<ul>
<li>Cline. 2025-05. <a href="https://cline.bot/blog/why-cline-doesnt-index-your-codebase-and-why-thats-a-good-thing">Why Cline Doesn't Index Your Codebase (And Why That's a Good Thing)</a>. Cline 有很多关于模型各种数据的博客.</li>
<li>minusx. 2025-08. <a href="https://minusx.ai/blog/decoding-claude-code/">What makes Claude Code so damn good (and how to recreate that magic in your agent)!?</a>. 大道至简</li>
<li>Multi-Agent<ul>
<li>Anthropic. 2025-06. <a href="https://www.anthropic.com/engineering/multi-agent-research-system">How we built our multi-agent research system</a></li>
<li>Cognition. 2025-06. <a href="https://cognition.ai/blog/dont-build-multi-agents">Don’t Build Multi-Agents</a></li>
</ul>
</li>
</ul>
<p><strong>Deep Research</strong></p>
<ul>
<li>Google. 2025-06. <a href="https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart">Gemini Fullstack LangGraph Quickstart</a>. 最基本的 agentic search pattern</li>
<li>LangChain. 2025-07. <a href="https://blog.langchain.com/open-deep-research/">Open Deep Research</a>. 结构和很清晰基础, 在搜索阶段分 topic 给 sub-agent 干活, 最后用一个 LLM 写报告. 比 Gemini Quickstart 多了最开始的澄清和计划步骤, 类似 Gemini 和 ChatGPT 中实际的 deep research. 也是基于 LangGraph 写的, 代码见 <a href="https://github.com/langchain-ai/open_deep_research">这里</a>.</li>
<li>Jina. 2025-02. <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/">DeepSearch/DeepResearch 实施实用指南</a>. Jina 擅长做 embedding, 技术博客里有很多和 RAG 相关的文章, 风格相比别家也比较 tech.</li>
<li>周星星-知乎. 2025-04. <a href="https://zhuanlan.zhihu.com/p/1898699101354332848">端到端的训练, 怎么复现 Deep ReSearch</a></li>
</ul>
<p><strong>Training: Agentic RL</strong></p>
<ul>
<li>2025-07. <a href="https://www.dbreunig.com/2025/07/30/how-kimi-was-post-trained-for-tool-use.html">How Kimi K2 Became One of the Best Tool-Using Models</a></li>
<li>2025-09. <a href="https://tongyi-agent.github.io/zh/blog/introducing-tongyi-deep-research/">通义 DeepResearch：开源 AI 智能体的新纪元</a></li>
</ul>
