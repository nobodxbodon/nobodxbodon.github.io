<h2>原文：<a href="https://shiina18.github.io/2020/09/03/dl-ts">Deep Learning for Time Series Probabilistic Forecasting</a></h2>
<hr/>
<p>title: "Deep Learning for Time Series Probabilistic Forecasting"
categories:</p>
<ul>
<li>Machine Learning
tags:</li>
<li>Time Series
updated:
comments: true
mathjax: true</li>
</ul>
<hr/>
<p>主要介绍 <a href="https://arxiv.org/pdf/1704.04110.pdf">DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks</a>, 其他方法暂时略讲. 附带讲一些我知道的统计学领域的方法. 例子依然主要以销量预测为例.</p>
<p>&lt;!-- more --&gt;</p>
<h2>Model</h2>
<p>尽量和原论文记号保持一致. 假设我们有 $N$ 条时间序列, $T$ 个时间点. 第 $i$ 条时间序列在时间 $t$ 的值记为 $z_{i, t}$, 特征记为 $x_{i,t}$ (向量). 为了符号简便, 去掉下标 $i$, 简记为 $z_t$, $x_t$. 记</p>
<p>$$
z_{t_1:t_2} := (z_{t_1}, z_{t_1+1},\dots, z_{t_2})
$$</p>
<p>为时间段 $[t_1, t_2]$ 的序列. 类似地定义 $x_{t_1:t_2}$, 并假设特征在所有时间点 (包括未来) 都是已知的. 假设历史序列时间段为 $[1, t_0-1]$, 未来为 $[t_0, T]$, 我们要建模条件似然</p>
<p>$$
P(z_{t_0:T} | z_{1:t_0-1}, x_{1:T}).
$$</p>
<p>假设模型的条件似然为</p>
<p>$$
Q_\Theta(z_{ t_0:T} | z_{1:t_0-1}, x_{1:T}) = \prod_{t=t_0}^T Q_\Theta(z_{t} | z_{1:t_0-1}, x_{1:T}) = \prod_{t=t_0}^T \ell(z_{t}|\theta(h_{t}, \Theta)),
$$</p>
<p>其中 (省略 $h$ 下标 $i$)</p>
<p>$$
h_t = f(h_{t-1}, z_{t-1}, x_t, \Theta),
$$</p>
<p>而  $f$ 表示多层 LSTM, 似然 $\ell$ 是根据指定的参数分布来取的 (如 Gauss, negative binomial).</p>
<p>生成预测样本的方法是迭代式 (很常见的做法): 根据选定的参数分布 sample 出一个值, 之后将这个值当成真实值继续 sample 下一个时间点的样本. 重复若干次, 再根据多条模拟样本估计感兴趣的分位数.</p>
<p><img alt="" src="https://shiina18.github.io/assets/posts/images/20200903163635743_23261.png"/></p>
<h3>Training</h3>
<p>Gauss 和 negative binomial 分布可以用一阶矩和二阶矩完全刻画, 神经网络干的事情就是学习这俩参数. 目标是极大化 log 似然</p>
<p>$$
\sum_{i=1}^N\sum_{t=t_0}^T \log \ell(z_{i, t}|\theta(h_{i,t})).
$$</p>
<p>特征: 价格, 促销, 'age' (the distance to the first observation in that time series), day-of-the-week, category embedding 等.</p>
<h3>Data Augmentation</h3>
<p>类似 cross-validation, 用一个 window 去截时间序列.</p>
<ul>
<li>比如 $t=1$ 可以从不同的时间点开始. 但是整个序列的长度依然保持为 $T$.</li>
<li>起始点 $t=1$ 可以放在最早的历史时间点之前, 用零填充. 这样可以让模型学到新序列的行为. (冷启动)</li>
<li>这样数据增强的目的是保证绝对时间的信息只能通过特征学到, 而不是根据 $z_t$ 在时间序列中的相对位置.</li>
</ul>
<h3>Scale Handling</h3>
<ul>
<li>对参数进行 item-dependent 的 scale $\nu_i$, 便于对不同 scale 的时间序列的学习.</li>
<li>序列不平衡. 有少量的物品销量会很大, 而销量大的物品和销量小的物品行为可能不同. 由于使用的是随机梯度下降, 如果我们均匀地从时间序列中抓几条来更新参数, 可能会导致销量大的物品欠拟合. 论文作者采用的方法是以学习到的 scale $\nu_i$ 作为权重进行采样, 这样销量大的物品会被多关照一些.</li>
<li>直接用均值作为 $\nu_i$ 在实际中效果不错.</li>
</ul>
<h3>State-Space Model</h3>
<p>模型结构很简单, 就是常见的 RNN 变种. AR (autoregressive) 就在于上一个时间点的真值会被用来预测当前时间点的值.</p>
<p>总得来说就是假设时间序列的条件分布服从某个参数分布, 而这个参数是用神经网络学来的, 目标是最大化条件似然. 整个结构实际上就是统计学中 state space model 的结构, 唯一区别在于 $f$ 被换成了神经网络. 实际上也有直接标题为深度学习 ssm 的文章 <a href="http://papers.nips.cc/paper/8004-deep-state-space-models-for-time-series-forecasting.pdf">Deep State Space Models for Time Series Forecasting</a>, 但我还没读.</p>
<p>说回统计学, 在 <a href="https://shiina18.github.io/machine%20learning/2020/08/15/ts-evaluations/">Some Evaluations for Time Series Forecasting</a> 里提到过销量属于计数时间序列, 关于计数时间序列的状态空间模型, 可以参考</p>
<ul>
<li>Davis, R. A., Holan, S. H., Lund, R., &amp; Ravishanker, N. (Eds.). (2016). <em>Handbook of discrete-valued time series</em>. CRC Press.</li>
</ul>
<p>专著, Davis 是老时间序列专家了. 一些综述可以在这里找到.</p>
<ul>
<li>Davis, R. A., &amp; Liu, H. (2016). Theory and inference for a class of nonlinear models with application to time series of counts. <em>Statistica Sinica</em>, 1673-1707.</li>
</ul>
<p>这篇我觉得证明很漂亮.</p>
<ul>
<li>Liu, M., Li, Q., &amp; Zhu, F. (2019). Threshold negative binomial autoregressive model. <em>Statistics</em>, <em>53</em>(1), 1-25.</li>
</ul>
<p>比较近的文章, 综述可以一看.</p>
<p>统计学更注重证明相关性质: 参数估计的相合性, 渐进正态性等.</p>
<h2>Implementation</h2>
<p>在 <a href="https://zhuanlan.zhihu.com/p/85644852">深度需求预测 (Deep Demand Forecast)</a> 中提到了几篇文章, 我看了作者关于 DeepAR 的 PyTorch 实现, 发现有明显的问题, 而且文章提到的一些 tricks 并没有实现. 后来看到了亚马逊的 gluonTS 包, 这里有一篇介绍 <a href="http://roseyu.com/time-series-workshop/submissions/2019/timeseries-ICML19_paper_33.pdf">Neural time series models with GluonTS Time Series Workshop ICML 2019</a>.</p>
<p>在 gluonTS 中, 其他深度时间序列的模型实现粗看都不如 deepar 的完整.</p>
<p>文档比较缺, 很多细节必须要读源码.</p>
<ul>
<li><a href="https://github.com/awslabs/gluon-ts/issues/469">time_features</a></li>
<li><a href="https://github.com/awslabs/gluon-ts/issues/335">data aug</a></li>
<li><a href="https://github.com/awslabs/gluon-ts/issues/637">hyper params tuning</a></li>
<li>官方教程里给出了定义 data transformation 的方法, 却从来没有用过它. 实际上各个 estimator 类都自带一个 transformer, 里面有一个 spliter 就是数据增强用的.</li>
<li>LSTM 的 dropout 使用的是 mxnet 的 zoneout.</li>
<li>虽然在 data 中可以定义 feat_dynamic_cat, 但是模型并不能使用这个特征.</li>
</ul>
