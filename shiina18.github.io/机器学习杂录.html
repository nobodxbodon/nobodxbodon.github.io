<h2>原文：<a href="https://shiina18.github.io/machine%20learning/2020/12/24/ml-misc">机器学习杂录</a></h2>
<hr/>
<p>title: "机器学习杂录"
categories:</p>
<ul>
<li>Machine Learning
updated: 2022-10-31
comments: true
mathjax: false</li>
</ul>
<hr/>
<p>只列举我读过的, 推荐的材料.</p>
<p>&lt;!-- more --&gt;</p>
<h2>Basics</h2>
<ul>
<li>周志华. (2016). 机器学习. 清华大学出版社.</li>
</ul>
<p>必读经典. 较为简明, 覆盖了各个话题. 由于封面印着西瓜, 书中以挑西瓜为例讲解, 故称西瓜书. 2020 年在 Springer 上出了 <a href="https://www.springer.com/gp/book/9789811519666">英文版</a>.</p>
<ul>
<li>李航. (2019). 统计学习方法 (第 2 版). 清华大学出版社.</li>
</ul>
<p>必读经典. 覆盖的话题较西瓜书少一些, 证明部分更多一些. 第二版增加了不少内容.</p>
<ul>
<li>Friedman, J., Hastie, T., &amp; Tibshirani, R. (2009). <em><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The elements of statistical learning (2nd ed.)</a></em>. New York: Springer series in statistics.</li>
</ul>
<p>著名的 ESL. 默认读者对统计和优化都有一定基础, 写法不太容易读. 另外一本 Christopher Bishop 的 PRML (Pattern Recognition and Machine Learning) 容易得多. <a href="https://probml.github.io/pml-book/">MLAPP</a> (Machine Learning: a Probabilistic Perspective) 比较新, 但我没读过.</p>
<ul>
<li>葫芦娃. (2018). 百面机器学习. 人民邮电出版社.</li>
</ul>
<p>可以用于查漏补缺. 另外还有一本叫《百面深度学习》, 不太推荐.</p>
<ul>
<li>Deep Learning Specialization @DeepLearning.AI</li>
</ul>
<p>吴恩达的经典课程. 入门介绍. 在 coursera 上也有, 另外民间有中文笔记和作业资源, 可以参考 <a href="https://github.com/fengdu78/deeplearning_ai_books">黄海广的 repo</a>.</p>
<ul>
<li>邱锡鹏. (2020). <a href="https://nndl.github.io/">神经网络与深度学习</a>. 机械工业出版社.</li>
</ul>
<p>数学推导写得清楚, 这点好评. 18 年左右就有电子版了, 20 年出版. 我不喜欢 Ian Goodfellow 的 <a href="https://www.deeplearningbook.org/">花书</a>, 我觉得没写清楚. 另外一提, <a href="https://d2l.ai/chapter_preface/index.html">dive into deep learning</a> 的数学记号写得也清楚, 一个特色是附带了详细的代码实现.</p>
<h2>NLP</h2>
<ul>
<li><a href="https://web.stanford.edu/class/cs224n/">CS224n: Natural Language Processing with Deep Learning @Stanford</a></li>
</ul>
<p>很著名的课了. Notes 写得好. 尤其是开头几个 notes (w2v 等), 其他网上的 notes 要么跳过细节, 要么语焉不详.</p>
<ul>
<li>Jurafsky, D., &amp; Martin, J. H. (2019). <em><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech &amp; language processing (3rd ed. draft)</a></em>.</li>
</ul>
<p>NLP 基本任务和知识. 新版还没写完. 是在李纪为 (Stanford NLP PhD, 香侬科技创始人) 的文章 <a href="https://zhuanlan.zhihu.com/p/59184256">初入 NLP 领域的一些小建议</a> 中看到的. 建议可以快速过一下深度学习部分, 其他部分按需阅读.</p>
<ul>
<li><a href="https://github.com/DA-southampton">DA-southampton</a></li>
</ul>
<p>在 repo 里包含了 NLP 相关知识, 以及大厂深度学习落地经验. 另有微信公众号: NLP从入门到放弃.</p>
<h2>Recommender system</h2>
<ul>
<li>项亮. (2012). 推荐系统实践. 人民邮电出版社.</li>
</ul>
<p>好的入门书. 主要介绍了各种传统方法. 代码错误巨多.</p>
<ul>
<li><a href="https://www.zhihu.com/people/wang-zhe-58">王喆</a>. (2020). 深度学习推荐系统. 电子工业出版社.</li>
</ul>
<p>较为系统地介绍了深度学习方法.</p>
<h2>Reinforcement learning</h2>
<ul>
<li><a href="https://spinningup.openai.com/en/latest/spinningup/rl_intro.html">OpenAI Spinning UP</a></li>
</ul>
<p>极简高质量的介绍, 同时提供了大量后续阅读材料. 我个人不喜欢蘑菇书 easy-rl 的写作. 不过后者我只看了第一章, 无法多做评论.</p>
<h2>Posts</h2>
<ul>
<li>Andrew Ng. <a href="https://www.deeplearning.ai/wp-content/uploads/2021/06/MLOps-From-Model-centric-to-Data-centric-AI.pdf">MLOps: From Model-centric to Data-centric AI</a></li>
<li>夕小瑶的卖萌屋. (2022). <a href="https://mp.weixin.qq.com/s/cVw05WElPWMUK9s6MFig0Q">算法工程师的三观测试</a></li>
<li>夕小瑶的卖萌屋. (2022). <a href="https://mp.weixin.qq.com/s/hnkDIqkao-_9CCG4G5zkcA">19 位算法工程师总结: 机器学习项目成功落地的三条秘诀</a> (MLOps)</li>
</ul>
<h2>Subscriptions</h2>
<p>微信公众号</p>
<ul>
<li>夕小瑶的卖萌屋 (xixiaoyaoQAQ): ML 全般</li>
<li>滴滴技术</li>
<li>美团技术团队: 有同名 <a href="https://tech.meituan.com/">技术博客</a>. 美团在技术分享方面做得特别好, 算法内容很多. 还有本书是《美团机器学习实践》, 完全不如直接读公众号.</li>
<li>DataFunTalk: 很多企业的机器学习实践</li>
<li>李rumor: NLP</li>
</ul>
<h2>Blogs, websites, and repos</h2>
<p>众所周知的就不列了. 博客参见 <a href="https://shiina18.github.io/about/">About</a> 页的 blogroll 一栏.</p>
<ul>
<li><a href="https://scikit-learn.org/stable/user_guide.html">User guide: contents — scikit-learn documentation</a>: Sklearn 的用户指南, 有些 topic 其实写得特别好, 比如 <a href="https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting">GBDT</a>. 我愿称之为最强用户指南.</li>
<li><a href="https://facebookresearch.github.io/Kats/">Facebook Kats: One stop shop for time series analysis in Python</a>: Facebook 最新的时间序列工具包, 包括了他们以前的工作 Prophet. 他家的 <a href="https://engineering.fb.com/">技术博客</a> 和 <a href="https://ai.facebook.com/blog/">AI 博客</a> 我没怎么读过.</li>
<li><a href="https://distill.pub/">Distill</a>: Illustrative, interactive, and informative.</li>
<li><a href="https://www.msra.cn/">微软亚洲研究院</a></li>
<li><a href="https://ai.googleblog.com/">Google AI Blog</a></li>
<li><a href="http://ai.stanford.edu/blog/">The Stanford AI Lab Blog</a></li>
<li><a href="https://hazyresearch.stanford.edu/blog">Hazy Research</a>: 以数据为中心. A CS research group at Stanford led by Professor Chris Ré interested in understanding those shifts and building the foundations for the next generation of machine learning systems.</li>
<li><a href="https://machinelearning.apple.com/research/">Apple Machine Learning Research</a></li>
<li><a href="https://bair.berkeley.edu/blog/">The Berkeley Artificial Intelligence Research Blog</a>: 强化学习</li>
<li><a href="https://ernestklchan.medium.com/">Ernest Chan</a>: 机器学习平台. 随机逛到的小哥, 喜欢他写的文章, 参考文章很有用. 顺附其他机器学习平台的资料<ul>
<li><a href="https://zhuanlan.zhihu.com/p/357897337">从小作坊到智能中枢: MLOps 简介</a></li>
<li><a href="https://github.com/cdfoundation/sig-mlops/blob/master/roadmap/2021/MLOpsRoadmap2021.md">MLOps Roadmap</a></li>
</ul>
</li>
<li><a href="https://eugeneyan.com/">eugeneyan</a> by Eugene Yan, an Applied Scientist at Amazon.</li>
<li><a href="https://openai.com/blog/">OpenAI</a>: 一些新奇应用</li>
<li><a href="https://engineering.linkedin.com/blog/topic/artificial-intelligence">Linkedin</a> 的 AI 文章</li>
<li><a href="https://eng.uber.com/category/articles/ai/">Uber Engineering</a></li>
</ul>
<h2>Others</h2>
<p>偏数学的书, 对 <strong>应用</strong> 机器学习而言不太重要.</p>
<ul>
<li>Boyd, S., &amp; Vandenberghe, L. (2004). <em><a href="https://web.stanford.edu/~boyd/cvxbook/">Convex optimization</a></em>. Cambridge university press.</li>
</ul>
<p>凸优化经典教材, 很容易读. 内容也比较实用. 优点是例子多, 缺点也是例子多 (本来几句话就能讲完).</p>
<ul>
<li>Nocedal, J., &amp; Wright, S. (2006). <em><a href="http://www.apmath.spbu.ru/cnsa/pdf/monograf/Numerical_Optimization2006.pdf">Numerical optimization</a></em>. Springer Science &amp; Business Media.</li>
</ul>
<p>优化经典教材. 写得挺好的, 需要时可以当字典查. 深度学习时代梯度下降大行其道, 书中内容对深度学习而言似乎不太有用.</p>
<ul>
<li>Cover, T. M. (2006). <em><a href="http://staff.ustc.edu.cn/~cgong821/Wiley.Interscience.Elements.of.Information.Theory.Jul.2006.eBook-DDU.pdf">Elements of information theory</a></em>. John Wiley &amp; Sons.</li>
</ul>
<p>信息论很好的参考书.</p>
<ul>
<li>Castro, R. (2018). <a href="https://www.win.tue.nl/~rmcastro/2DI70/files/2DI70_Lecture_Notes.pdf">2DI70 - Statistical Learning Theory Lecture Notes</a>.</li>
</ul>
<p>本科时用过的讲义, 讲 PAC learning, VC dimension 等理论 (learning theory). 可作为简单易读的科普. 国内比较有名的相关课程是林轩田的机器学习基石, 看起来主要内容大差不差, 所以我完全没看过.</p>
