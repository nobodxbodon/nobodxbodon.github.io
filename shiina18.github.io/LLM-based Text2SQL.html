<h2>原文：<a href="https://shiina18.github.io/2023/12/25/text2sql">LLM-based Text2SQL</a></h2>
<hr/>
<p>title: "LLM-based Text2SQL"
categories:</p>
<ul>
<li>Machine Learning
tags: NLP
updated:
comments: true
mathjax: false</li>
</ul>
<hr/>
<p>Gao, D., Wang, H., Li, Y., Sun, X., Qian, Y., Ding, B., &amp; Zhou, J. (2023). <a href="https://arxiv.org/pdf/2308.15363.pdf">Text-to-sql empowered by large language models: A benchmark evaluation</a>. <em>arXiv preprint arXiv:2308.15363</em>.</p>
<p>个人总结: 一篇 LLM 在 Text2SQL 数据集上的 prompt engineering 的实验报告. 在文中评测的两个数据集中效果是开源方案中最好的. 提出的 prompt 方案 DAIL-SQL 融合了现有的几种 RAG 方法.</p>
<p>&lt;!-- more --&gt;</p>
<h2>数据集</h2>
<ul>
<li><a href="https://yale-lily.github.io/spider">Spider</a> is a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students. It consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables covering 138 different domains.</li>
</ul>
<p>实际上看给出的 Data Examples, 即使是 EXTRA HARD 的样例, 涉及的数据库和 SQL 相比实际都相当简单.</p>
<blockquote>
<p>[Extra Hard] What is the average life expectancy in the countries where English is not the official language?</p>
</blockquote>
<pre><code class="language-sql">SELECT AVG(life_expectancy)
FROM country
WHERE name NOT IN 
   (SELECT T1.name
    FROM country AS T1 JOIN
    country_language AS T2
    ON T1.code = T2.country_code
    WHERE T2.language = "English"
      AND T2.is_official = "T")
</code></pre>
<ul>
<li><a href="https://bird-bench.github.io/">BIRD</a> (<strong>BI</strong>g Bench for La<strong>R</strong>ge-scale <strong>D</strong>atabase Grounded Text-to-SQL Evaluation) contains over 12,751 unique question-SQL pairs, 95 big databases with a total size of 33.4 GB. It also covers more than 37 professional domains, such as blockchain, hockey, healthcare and education, etc.</li>
</ul>
<h2>评价指标</h2>
<ul>
<li>Execution Accuracy. 这个指标有很多种叫法. 生成的 SQL 执行结果是否与答案 SQL 结果相同.</li>
<li>Exact Set Match. 把 SQL 分解成若干子句, 每个子句再拆成词的集合. 弄成集合规避顺序问题, 比如 <code>SELECT col1, col2</code> 和 <code>SELECT col2, col1</code> 等价. 详见 <a href="https://github.com/taoyds/spider/tree/master/evaluation_examples">这里</a>.</li>
<li>Valid Efficiency Score. 首先执行结果要符合答案, 其次评估效率.</li>
</ul>
<h2>Prompts</h2>
<h3>Question Representation</h3>
<ul>
<li>Basic Prompt. 给出相关表的 schemas, 接上 QA, 并以 <code>A: SELECT</code> 提示模型补全. 没有 instruction.</li>
</ul>
<pre><code>Table continents, columns = [ContId, Continent]
Table countries, columns = [CountryId, CountryName, Continent]
Q: How many continents are there?
A: SELECT
</code></pre>
<ul>
<li>Text Representation Prompt. 在 Basic Prompt 基础上加上 instructions.</li>
</ul>
<pre><code>Given the following database schema:
continents: ContId, Continent
countries: CountryId, CountryName, Continent

Answer the following: How many continents are there?
SELECT
</code></pre>
<ul>
<li>OpenAI Demostration Prompt. 当成 SQL 让模型补全, 把指示信息放在注释.</li>
</ul>
<pre><code class="language-sql">### Complete sqlite SQL query only and with no explanation
### SQLite SQL tables, with their properties:
#
# continents (ContId, Continent)
# countries (CountryId, CountryName, Continent)
#
### How many continents are there?
SELECT
</code></pre>
<ul>
<li>Code Representation Prompt.</li>
</ul>
<pre><code class="language-sql">/* Given the following database schema: */
CREATE TABLE continents (
    ContId int primary key,
    Continent text,
    foreign key (ContId) references countries (Continent)
);

CREATE TABLE countries (
    CountryId int primary key,
    CountryName text,
    Continent int,
    foreign key (Continent) references continents (ContId)
);

/* Answer the following: How many continents are there? */
SELECT
</code></pre>
<ul>
<li>Alpaca SFT Prompt.</li>
</ul>
<pre><code class="language-markdown">Below is an instruction that describes a task, paired
with an input that provides further context. Write a
response that appropriately completes the request.

### Instruction:
Write a SQL query to answer the question "How many continents are there?"

### Input:
continents (ContId, Continent)
countries (CountryId, CountryName, Continent)

### Response:
SELECT
</code></pre>
<h3>In-Context Learning</h3>
<p>考虑 k-shot: 从训练集 (question-sql pairs) 中选 k 个放入 prompt.</p>
<ul>
<li>Random.</li>
<li>Question Similarity Selection. 根据 question 相似度 kNN.</li>
<li>Masked Question Similarity Selection. 把 question 中的领域相关的表名, 列名, 值等 mask 掉, 再 kNN.</li>
<li><strong>Query Similarity Selection.</strong> It employs a preliminary model to generate SQL query $s'$ using target question and database, where this generated $s'$ can be regarded as an approximation of target SQL query $s^\ast$. Then it encodes queries from examples into binary discrete syntax vectors according to their keywords. After that, it chooses $k$ examples by considering both similarity to the approximated query $s'$ and diversity among selected examples.</li>
</ul>
<p><strong>Example Organization</strong></p>
<ul>
<li>Full-Information Organization.</li>
</ul>
<pre><code class="language-sql">/* Given the following database schema: */
${DATABASE_SCHEMA}
/* Answer the following: How many authors are there? */
SELECT COUNT(*) FROM authors

/* Given the following database schema: */
${DATABASE_SCHEMA}
/* Answer the following: How many farms are there? */
SELECT COUNT(*) FROM farm

${TARGET_QUESTION}
</code></pre>
<ul>
<li>SQL-Only Organization.</li>
</ul>
<pre><code class="language-sql">/* Some SQL examples are provided based on similar problems: */
SELECT COUNT(*) FROM authors

SELECT COUNT(*) FROM farm

${TARGET_QUESTION}
</code></pre>
<h3>DAIL-SQL</h3>
<p>这篇论文提出的方法, 缝合了上述所有方法.</p>
<ul>
<li>用 Code Representation Prompt 表示 question.</li>
<li><strong>Selection.</strong> Consider both questions and queries to select candidates. Specifically, DAIL Selection first masks domain-specific words in both target question $q$ and example questions $q_i$ in the candidate set. It then ranks the candidate examples based on the Euclidean distance between the embeddings of masked $q$ and $q_i$. Simultaneously, it calculates the query similarity between the pre-predicted SQL query $s'$ and $s_i$ in the candidate set. Finally, the selection criterion prioritizes the sorted candidates by question similarity with a query similarity greater than a predefined threshold. In this way, the selected top $k$ examples have good similarity with both question and query.</li>
<li><strong>Organization.</strong> Preserve the mapping information between questions and
SQL queries and also improve the token efficiency. 缝合两种 organization 但是省些 token.</li>
</ul>
<pre><code class="language-sql">/* Some example questions and corresponding SQL queries are provided based on similar problems: */

/* Answer the following: How many authors are there? */
SELECT COUNT(*) FROM authors

/* Answer the following: How many farms are there? */
SELECT COUNT(*) FROM farm

${TARGET_QUESTION}
</code></pre>
<p>最后是用这套 prompt 在 GPT-4 上达到 sota. 微调则是对开源小 LLM 进行, 因为没钱调 GPT-4.</p>
<h2>其他</h2>
<ul>
<li><a href="https://arxiv.org/abs/2203.11171">Self-Consistency Improves Chain of Thought Reasoning in Language Models</a> 文中用这个 trick 提升了很少的点, 问题是耗时增加多倍.</li>
<li><a href="https://github.com/eosphoros-ai/Awesome-Text2SQL">Awesome-Text2SQL</a></li>
<li><a href="https://scale.com/blog/text2sql-fine-tuning">We Fine-Tuned GPT-4 to Beat the Industry Standard for Text2SQL</a> 微调了 GPT-4, 但是效果还没别人 prompt engineering 好. 人家强调别人针对数据集做了特殊处理, 他们这个更通用. 不知道实际如何.</li>
</ul>
