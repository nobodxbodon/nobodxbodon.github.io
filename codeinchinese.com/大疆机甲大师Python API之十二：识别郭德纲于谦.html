<h2>原文：[大疆机甲大师Python API之十二：识别郭德纲于谦](https://codeinchinese.com/2019/11/06/大疆机甲大师Python API之十二：识别郭德纲于谦.markdown)</h2>
<hr/>
<h2>layout: post
comments: true
title:  大疆机甲大师Python API之十二：识别郭德纲于谦
description:
date:   2019-11-06 00:00:00 -0700
categories: Python 机甲大师</h2>
<p>为测试识别行人相关接口，先用手机端对真人（自己）作了行人识别尝试，发觉对全身像比较敏感。接着用照片试了试，感觉站姿更易于被识别。</p>
<p>为了使实验易于重复，选择在电脑播放视频并静止画面。将机甲摄像头设置为高清，似乎效果好了点。下面是搭建的环境：
![2019-11-06_setup]({{ "/assets/2019-11-06_setup.png" | absolute_url }})</p>
<p>手机端开发环境中，先测试了手动使能行人识别的效果。垫高了电脑，调整距离，使识别效果稳定。见手机截图中的两个黄框：</p>
<p>![2019-11-06_cell识别]({{ "/assets/2019-11-06_cell识别.png" | absolute_url }})</p>
<h3>代码主体</h3>
<pre><code class="language-python">def 开始():
    视觉.开启识别(行人)
    
    while True:
        if 视觉.当识别到(常量.有行人时):
            信息 = 视觉.取行人信息()
            告知(信息)
        时间.睡眠(1)
</code></pre>
<p>在机甲上完整可运行代码<a href="https://github.com/program-in-chinese/robomaster-python-samples-zh/blob/master/Python%20API%E8%A7%86%E9%A2%91%E6%BC%94%E7%A4%BA%E4%B8%8E%E4%BE%8B%E7%A8%8B/%E8%AF%86%E5%88%AB/%E8%A1%8C%E4%BA%BA.py">在此</a>。每隔一秒尝试一次识别行人，在控制台输出识别信息，格式如下（源自<a href="https://www.dji.com/cn/robomaster-s1/programming-guide">官方文档</a>）：</p>
<p>![2019-11-06_api文档]({{ "/assets/2019-11-06_api文档.png" | absolute_url }})</p>
<h3>测试结果</h3>
<p>过程中机甲位置没动，识别距离未作修改。</p>
<p>一、两人识别：
![2019-11-06_api识别2]({{ "/assets/2019-11-06_api识别2.png" | absolute_url }})</p>
<p>二、郭德纲识别：
![2019-11-06_api识别左]({{ "/assets/2019-11-06_api识别左.png" | absolute_url }})</p>
<p>中心点位置和两人识别时区别不大，宽度也差不多，但高度高了10%。这个，难道是没有谦大爷衬托就显高了？</p>
<p>三、于谦识别：
![2019-11-06_api识别右]({{ "/assets/2019-11-06_api识别右.png" | absolute_url }})</p>
<p>光是谦大爷的话，识别的位置上移了点，也胖点高点。</p>
<p>四、如果挡了腿，就识别不到了
![2019-11-06_api识别0]({{ "/assets/2019-11-06_api识别0.png" | absolute_url }})
仔细看看题图里的识别，感情是把桌子认成了谦大爷的裙子哈。</p>
<h3>后感</h3>
<p>希望放开底层接口，以便进行视觉识别的算法尝试。比如能获得视频流（或者帧）的话，再加上对第三方库的支持，用户就可以实现一些初步的人脸、物品识别等等。想起来就很美！</p>
