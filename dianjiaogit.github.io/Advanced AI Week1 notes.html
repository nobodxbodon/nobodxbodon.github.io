<h2><a href="https://github.com/dianjiaogit/dianjiaogit.github.io/blob/master/_posts/2019-12-29-week1 notes.md">仓库源文</a>，<a href="https://dianjiaogit.github.io/advanced%20ai/2019/12/29/week1-notes">站点原文</a></h2>
<hr/>
<p>layout: post
title:  "Advanced AI Week1 notes"
date:   2019-12-29 19:11:01 +0800</p>
<h2>categories: [Advanced AI]</h2>
<p>Goal of Artificial General Intelligence (AGI): \
Build general-purpose Super-Intelligences</p>
<p>HOW??? \
--&gt; Build system by trail &amp; error (Artificial Approach) \
--&gt; Mimic human behavior (Natural Approach) (Not covered in this course)</p>
<p>So we need THEORIES to guide us.</p>
<p>For Artificial Approach:</p>
<ul>
<li>AI system includes: <ul>
<li>Logic/language based </li>
<li>Economics inspired </li>
<li>Cybernetics </li>
<li>Machine Learning </li>
<li>Information processing</li>
</ul>
</li>
</ul>
<hr/>
<p>\
Intelligence does not have a formal definition yet.</p>
&lt;pre&gt;
Humanly Thinking:   Cognitive Science
Humanly Acting:     Turing test, Behaviorism
Rationally Thinking:    Laws Thought
Rationally Acting:  Doing the Right Thing (the topic we discuss)
&lt;/pre&gt;<p><strong>Decision Theory = Probability + Utility Theory</strong>\
Uncertain world, environmental probability distribution is <em>known</em>.</p>
<p><strong>Universal Induction = Ockham + Bayes + Turing</strong>\
Sequence prediction for <em>unknown</em> prior distribution.</p>
<p><strong>AI = Decision Theory + Universal Induction</strong></p>
<hr/>
<p>\
UAI covers all Reinforcement Learning(RL) problem types<br/>
--&gt; Statistical Machine Learning:<br/>
Mostly independent and identically distributed(i.i.d.) data classification, regression, clustering<br/>
--&gt; RL Problems &amp; Algorithms:<br/>
Stochastic, unknown, non-i.i.d. environments<br/>
--&gt; Artificial Intelligence:<br/>
Traditionally deterministic, known world/planning problem</p>
<hr/>
<p>\
Informal Definition of Intelligence:<br/>
Intelligence measures an agent's ability to achieve goals in a wide range of environments.</p>
<p>Induting a model of the environment --&gt; Make predictions --&gt; Make a decision --&gt; Do the next action</p>
<h2>Induction:</h2>
<p><strong>Occam's razor</strong>: Take simplest hypothesis consistent with data.</p>
<p>Then how to quantify "simplicity"?<br/>
Description Length!</p>
<p>--&gt; Shortest description of object is best explanation.</p>
<p>Shortest description = Shortest prgram for a string on a Turing Machines T --&gt; Best extrapolation = Prediction</p>
<p>$$K<em>T(x) = \min</em>{p}{\ell(p) : T(p) = x}$$</p>
<p><strong>Kolmogorov-complexity(x):</strong><br/>
$$K(x) = K_U(x) \leq K_T(x) + c_T$$</p>
<p>However, K(x) is uncomputable and p can not be easily found.</p>
<p>So we need to have prior for each possible p. That is why we introduce Bayes' rule here.</p>
<p><strong>Bayes' rule:</strong><br/>
$$P(H_i | D) = \cfrac{P(D|H_i) \cdot P(H<em>i)}{\sum</em>{i}P(D|H_i) \cdot P(H_i)}$$</p>
<p>$P(H_i)$ is prior probability.<br/>
$P(H_i|D)$ is posterior probability.</p>
<p>$P(D | H_i)$ is easy to describe.<br/>
But we do not know how to choose $P(H_i)$.</p>
<p><strong>Epicurus</strong>: If more than one theory is consistent with the observations, keep all theories.<br/>
So we refine Occam's razor with Kolmogorov complexity:
$$P(H<em>i) := 2^{-K</em>{T/U}(H_i)}$$</p>
<p>But if we use T, we do not know how to choose T.<br/>
If we use U, it is incomputable.</p>
<p><strong>Solomonoff</strong> combined Occam, Epicurus, Bayes and Turing. --&gt; Theory of sequential prediction</p>
<p>$M(x)$ = P(UTM outputs x when input is random)<br/>
$M(y|x) = M(xy)/M(x)$</p>
<p><strong>The Minimum Description Length Principle</strong><br/>
$y$ of highest $M(y|x)$ = $y$ of smallest $K_T(xy)$.</p>
<p>$x$ similar to $y$ --&gt; $K(x|y) := \min \{\ell(p) : U(p,y) = x\}$</p>
