<h2><a href="https://github.com/jasonkayzk/jasonkayzk.github.io/blob/master/source/_posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%AE%80%E8%BF%B0.md">仓库源文</a>，<a href="https://jasonkayzk.github.io/2021/03/25/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%AE%80%E8%BF%B0">站点原文</a></h2>
<hr/>
<h2>title: 操作系统内存管理简述
toc: true
cover: 'https://img.paulzzh.com/touhou/random?92'
date: 2021-03-25 10:19:11
categories: 技术杂谈
tags: [技术杂谈, 操作系统, 内存管理]
description: 内存管理是操作系统中一个关键的组成部分，本文通过C++实例，简述了操作系统中的内存管理；</h2>
<p>内存管理是操作系统中一个关键的组成部分，本文通过C++实例，简述了操作系统中的内存管理；</p>
<p>视频参考：</p>
<ul>
<li><a href="https://www.bilibili.com/video/BV1u7411z7Sv">【OS】操作系统的内存管理简介</a></li>
</ul>
<p>&lt;br/&gt;</p>
<p>&lt;!--more--&gt;</p>
<h2><strong>操作系统内存管理简述</strong></h2>
<h3><strong>为什么要有逻辑地址</strong></h3>
<p>由于程序无法知道实际可用的物理地址，所以必须对实际的内存地址做出映射！</p>
<blockquote>
<p>&lt;font color="#f00"&gt;<strong>如果有过单片机开发经验的同学应该知道，在进行嵌入式编程的时候，通常我们可以直接操作实际内存的物理地址，但是在操作系统中，都是使用逻辑地址的；</strong>&lt;/font&gt;</p>
</blockquote>
<p>使用逻辑地址，可以简化程序的开发，让所有的程序都以为他们拥有了操作系统的全部内存空间；</p>
<p><strong>并且可以避免恶意程序可以跨代码段对其他程序进行恶意修改；（但是，恶意程序其实还是可以通过共享库的方式恶意入侵其他程序）</strong></p>
<p>&lt;font color="#f00"&gt;<strong>如：C++中如果跨内存进行访问就会抛出Segment Fault的经典错误；</strong>&lt;/font&gt;</p>
<p>&lt;br/&gt;</p>
<h3><strong>逻辑地址和物理地址映射方法</strong></h3>
<h4><strong>① 固定偏移量</strong></h4>
<p><img alt="固定偏移量.png" src="https://raw.gitmirror.com/JasonkayZK/blog_static/master/images/%E5%9B%BA%E5%AE%9A%E5%81%8F%E7%A7%BB%E9%87%8F.png"/></p>
<p>即每个程序都使用一段连续的内存空间进行映射；</p>
<p>优点是实现起来简单，但是缺点很明显：</p>
<p>首先，每个程序使用的内存大小是不确定的；</p>
<p>如果我们预估程序1使用的最大内存为200，则程序1在整个执行过程中的内存占用率都会小于200，此时称内存中产生了<strong>内碎片</strong>；</p>
<p>其次，当程序1结束使用，而程序3占用空间为201时，原来连续的200个空间，其实是无法被使用的，如下图：</p>
<p><img alt="固定偏移量2.png" src="https://raw.gitmirror.com/JasonkayZK/blog_static/master/images/%E5%9B%BA%E5%AE%9A%E5%81%8F%E7%A7%BB%E9%87%8F2.png"/></p>
<p>此时0-200的区域被称为内存的<strong>外碎片</strong>；</p>
<p>为了减少这些内存碎片，使用分页的思想进行处理；</p>
<p>&lt;br/&gt;</p>
<h4><strong>② 内存分页</strong></h4>
<p>内存分页是指将内存按照固定的大小进行拆分，拆分后的物理内存被分为了多个帧(page frame)，程序的逻辑内存在加载时也被拆分为了多个页(page)，如下图：</p>
<p><img alt="内存分页.png" src="https://raw.gitmirror.com/JasonkayZK/blog_static/master/images/%E5%86%85%E5%AD%98%E5%88%86%E9%A1%B5.png"/></p>
<p>逻辑内存和物理内存直接的映射通过页表(Page Table)来维护，如下图：</p>
<p><img alt="页表.png" src="https://raw.gitmirror.com/JasonkayZK/blog_static/master/images/%E9%A1%B5%E8%A1%A8.png"/></p>
<blockquote>
<p>除了映射之外，页表存储了大量的信息：</p>
<ul>
<li>当前条目是否可用；</li>
<li>当前页的读写权限；</li>
<li>是否是脏读帧；</li>
<li>……</li>
</ul>
</blockquote>
<p>因为每个进程之间的存储空间都是相互独立的（共享库等其他特殊数据除外），所以页表是每个进程都需要维护的，如下：</p>
<p><img alt="页表2.png" src="/media/wwww/share/study/聚聚/源数据/博客聚合/jasonkayzk.github.io/source/_posts/"/></p>
<blockquote>
<p><strong>补充内容：</strong></p>
<ol>
<li><strong>内存的一个地址里面"住"的是一个字节(Byte)的数据；</strong></li>
<li><strong>2^32 位的操作系统的物理地址有 2^32 个，因而只能使用4GB的内存；</strong></li>
<li><strong>任何一个32位的程序可操作的逻辑地址都是2^32个即4GB；(每个32位的程序都天真的以为自己拥有4GB内存)</strong></li>
<li><strong>上面势必造成多个程序使用内存总和很有可能大于物理内存，此时会借助磁盘，将并不着急使用的内存先放到磁盘，此时PageTable对应的帧号只显示是磁盘；</strong></li>
</ol>
</blockquote>
<p>&lt;br/&gt;</p>
<h3><strong>记一次内存映射的过程</strong></h3>
<p>假设我们使用的机器为32为操作系统，我们一共具有256MB内存，每一页的大小为4KB；</p>
<p>而由于4K的数据可以使用12bit来寻址（4K = 4 X 1024Byte = 4 x 2^12 = 2 ^14）则有：</p>
<ul>
<li>逻辑地址（所有程序都认为自己是4GB）：32bit = 20bit页号 + 12bit偏移；</li>
<li>物理地址（实际只有256MB内存）：28bit = 16bit帧号 + 12bit偏移；</li>
</ul>
<p>以地址<code>0X000011A3</code>为例，其逻辑地址为：页号：00001，偏移：1A3；</p>
<p>接下来去看其在物理地址的映射；</p>
<p>假设该页号在Page Table中对应的真正物理内存的帧号为00F3（16bit），则会在物理内存帧号为00F3，偏移为1A3的区域寻找真正的数据，如下图：</p>
<p><img alt="内存映射.png" src="https://raw.gitmirror.com/JasonkayZK/blog_static/master/images/%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84.png"/></p>
<p>&lt;br/&gt;</p>
<p>但是，如果寻址之后，发现在物理内存中对应的帧号是磁盘会发生什么呢？</p>
<p>当映射的帧号是disk时，即映射到了磁盘上；<strong>此时会触发缺页异常，进入内核态，内核从磁盘中读取缺的这页内容，将其加载到物理内存中；</strong></p>
<p><strong>但是物理内存的帧有可能所有帧都满了，此时就需要逐出不太"重要"的帧（例如，使用LRU算法）；</strong></p>
<p>逐出的过程需要判断当前物理页(帧)是否是脏的（脏：与磁盘中内容不一致，即从磁盘加载到物理内存后被改过就是脏的），如果是脏的还需要更新磁盘中的内容保证一致；</p>
<p><strong>逐出后就腾出了位置给从磁盘中读到的这页的数据，然后需要更新页表的这一项的映射关系，将磁盘改为帧号，然后重新进行查页表这一步；</strong></p>
<blockquote>
<p>分页小结：</p>
<ul>
<li><strong>分页使得每个程序都有很大的逻辑地址空间，通过映射磁盘和高效的置换算法，使内存“无限大”；</strong></li>
<li><strong>分页使不同的进程的内存隔离，保证了安全；</strong></li>
<li><strong>分页降低了内存碎片问题；</strong></li>
</ul>
<p><strong>但是上述分页过程中，需要两次读内存时间上有待优化，页表占用空间较大空间上也有待优化；</strong></p>
</blockquote>
<p>&lt;br/&gt;</p>
<h3><strong>分页中的时间和空间优化</strong></h3>
<p>由上面的分析可知，要真正获取一个内存中的内容实际需要加载两次内存：一次是读取页表，一次是根据页表找到对应内存,因此可以进行时间上的优化；</p>
<p>并且，每个进程都需要维护一个页表，页表本身也是占内存空间的，因此也可以进行空间的优化；</p>
<h4><strong>时间优化</strong></h4>
<p>将最常访问的几个(一般8-128个左右)页表项储存到访问速度更快的硬件中，一般是在MMU（内存管理单元），这个小表的名称为**TLB (Translation Lookaside Buffer) **，可以称其为快表；</p>
<p>在寻址时，会先查询TLB，在miss后再查PT；</p>
<p>快表的命中率很高，这是由于程序的局部性原理，并且程序最常访问的页没几个；</p>
<blockquote>
<p>其实本质上就是缓存的策略；</p>
<p><strong>所以，这样的缓存就带来了程序并发执行的可见性问题；</strong></p>
</blockquote>
<h4><strong>空间优化</strong></h4>
<p>由于页表本身也占用内存，所以引入多级页表；</p>
<p>如上32位的系统和程序，一个程序要访问所有逻辑空间需要 2^20 个页面，对应2^20 个页表项；</p>
<p>如果每个页表项占4B的空间(32bit=4B)，则一个程序维护的页表将占用4MB的物理内存！</p>
<blockquote>
<p>4MB看起来很小，但是操作系统是要运行很多程序的！</p>
</blockquote>
<p>如果使用多级页表，将23位分为4位、4位、12位的分级方式，最后一级指向物理地址，而第一级指向第二级，第二级指向第三级；</p>
<p>如果发现第一级只有3项指向第二级，且第二级的都有效，则只需要3*2^4=48个页表项；</p>
<p>&lt;br/&gt;</p>
<h3><strong>程序内部的内存管理-分段</strong></h3>
<p>每个段有很多页，页表中存储段号和页号唯一映射物理地址帧号，即通过段号和页找找到唯一映射的帧号；严格意义的分段是，每一段的虚拟地址都是从0开始，然后页表是段号+页号来映射帧号的；</p>
<p><strong>但是这种形式已经被废弃了，只有x86 32位的intel的cpu还保留了这种段页结合的方式，即严格意义的分段已经用的很少；</strong></p>
<p>那为什么还经常听到段的概念？</p>
<p>&lt;font color="#f00"&gt;<strong>现在所说的段一般是程序在逻辑层面保留的概念，对逻辑地址有个粗略的划分，便于程序编写，但是并不影响os的内存管理（还是分页管理）；</strong>&lt;/font&gt;</p>
<p>以32位程序为例，如下图：</p>
<p><img alt="程序分段.png" src="https://raw.gitmirror.com/JasonkayZK/blog_static/master/images/%E7%A8%8B%E5%BA%8F%E5%88%86%E6%AE%B5.png"/></p>
<p>在逻辑空间中最高的0xc0000000 - 0xffffffff 这1G的内存是给内核留出的，剩余3G内存从低到高分别是Text、Data、Heap、Lib、Stack；</p>
<p>Heap是从低往高增长，Stack是从高往低增长，且有个最大限制；</p>
<p>Data存储静态变量Text存储程序二进制码；</p>
<p>Lib存储库函数需要占用的内存，多个程序如果都使用了相同的库，内存是共用的（共享内存）；</p>
<p>同时各个部分的留有随机的一段偏移量，可以保护程序，这也使得每次执行程序的时候变量所在的内存地址总是不同的；</p>
<blockquote>
<p>&lt;font color="#f00"&gt;<strong>注：分段是逻辑空间上的，不影响分页的内存管理方式，后面进行分页，映射到物理内存上各部分跨多个页其实并不连续；</strong>&lt;/font&gt;</p>
</blockquote>
<p>下图是两个程序在物理内存中的映射：</p>
<p><img alt="两个程序的内存映射.png" src="https://raw.gitmirror.com/JasonkayZK/blog_static/master/images/%E4%B8%A4%E4%B8%AA%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84.png"/></p>
<p>首先，Kernel部分的内存所有程序是共享的；</p>
<p>其次，他们有各自的堆区和栈区；</p>
<p>而对于Libraries区，则存在多个进程共享一个或者多个库（如Windows下的DLL或者Linux下的.so库）；</p>
<p>&lt;br/&gt;</p>
<h3><strong>Cache</strong></h3>
<p>CPU的三级缓存扮演着缓存主存数据的作用，而Cache在内存管理中的位置是怎样的呢？</p>
<p>PIPT：物理级cache，cpu分析完映射关系，先到Cache找有没有该物理地址的cache，这样会非常的慢，但是所有进程可以共享cache；</p>
<p>VIVT：逻辑级cache，cpu直接通过逻辑地址找cache，miss后再查TLB页表这些；这样很快，但是逻辑地址只能对当期进程使用，其他进程完全不能复用，尤其是库函数这种共享的不能利用好cache；</p>
<p>VIPT，将两者结合，用逻辑地址查找cache，cache中数据部分前面添加一个对应物理地址的tag；这样拿到这个tag后到tlb、页表中查看下这个对应关系是否正确，如果正确就直接读cache。这样速度和共享性都是折中的；</p>
<p>以上三种方式各有优劣，在不同的cpu中可能使用的不一样；</p>
<p>&lt;br/&gt;</p>
<h3><strong>磁盘映射mmap与缺页异常</strong></h3>
<p>在<a href="#%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84%E7%9A%84%E8%BF%87%E7%A8%8B">记一次内存映射的过程</a>的最后讲述了，如果页表映射到了磁盘的时候就会触发缺页异常，而这个过程其实是非常非常慢的；</p>
<p>建立磁盘与内存页映射关系有专门的系统调用：mmap；</p>
<p>mmap其实经常用在一些数据库的底层实现上，其实现原理大概就是：将数据文件映射到逻辑地址中；</p>
<p>而在进行查询的时候，是直接查询一个虚拟内存地址，然后首次访问可能会比较慢（缺页），但读取一次之后这页就补全了，后面访问该页的速度就会变快；</p>
<blockquote>
<p><strong>当然还是有很多细节的，比如：什么时候该逐出，页替换算法如何优化；</strong></p>
</blockquote>
<p>&lt;br/&gt;</p>
<h2><strong>附录</strong></h2>
<p>更多内容推荐看：</p>
<ul>
<li>CSAPP</li>
<li><a href="https://github.com/JasonkayZK/self-cultivation-in-programmer">《程序员的自我修养》</a></li>
</ul>
<p>&lt;br/&gt;</p>
