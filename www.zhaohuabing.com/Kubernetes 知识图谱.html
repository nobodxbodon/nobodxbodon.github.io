<h2><a href="https://github.com/zhaohuabing/hugo_blog/blob/master/content/post/2020-02-22-k8s-mindmap.md">仓库源文</a>，<a href="https://www.zhaohuabing.com/post/2020-02-22-k8s-mindmap">站点原文</a></h2>
<p><a href="/mindmap/k8s.html">Mind Map</a></p>
<ul>
<li>Kubernetes<ul>
<li>基本理念<ul>
<li>自动化部署，缩扩容和管理容器应用</li>
<li>预期状态管理(Desired State Management)<ul>
<li>Kubernetes API 对象（声明预期状态）</li>
<li>Kubernetes Control Plane（确保集群当前状态匹配预期状态）<ul>
<li>Kubernetes Master<ul>
<li>kube-apiserver（API Server）<ul>
<li>  - 对外提供各种对象的CRUD REST接口
  - 对外提供Watch机制，通知对象变化
  - 将对象存储到Etcd中</li>
</ul>
</li>
<li>kube-controller-manager（守护进程）<ul>
<li>  - 功能：通过apiserver监视集群的状态，并做出相应更改，以使得集群的当前状态向预期状态靠拢
  - controllers
      - replication controller
      - endpoints controller
      - namespace controller
      - serviceaccounts controller
      - ......</li>
</ul>
</li>
<li>kube-scheduler（调度器）<ul>
<li> - 功能：将Pod调度到合适的工作节点上运行
 - 调度的考虑因素
     - 资源需求
     - 服务治理要求
     - 硬件/软件/策略限制
     - 亲和以及反亲和要求
     - 数据局域性
     - 负载间的干扰
     - ......</li>
</ul>
</li>
</ul>
</li>
<li>Work Node<ul>
<li>Kubelet（节点代理）<ul>
<li>  - 接受通过各种机制（主要是通过apiserver）提供的一组PodSpec
  - 确保PodSpec中描述的容器处于运行状态且运行状况良好</li>
</ul>
</li>
<li>Kube-proxy（节点网络代理）<ul>
<li>  - 在节点上提供Kubernetes API中定义Service
  - 设置Service对应的IPtables规则
  - 进行流量转发（userspace模式）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>部署模式<ul>
<li>Single node</li>
<li>Single head node，multiple workers<ul>
<li>API Server，Scheduler，and Controller Manager run on a single node</li>
</ul>
</li>
<li>Single etcd，HA heade nodes，multiple workers<ul>
<li>Multiple API Server instances fronted by a load balancer</li>
<li>Multiple Scheduler and Controller Manager instances with leader election</li>
<li>Single etcd node</li>
</ul>
</li>
<li>HA etcd，HA head nodes，multiple workers<ul>
<li>Multiple API Server instances fronted by a load balancer</li>
<li>Multiple Scheduler and Controller Manager instances with leader election</li>
<li>Etcd cluster run on nodes seperate from the Kubernetes head nodes</li>
</ul>
</li>
<li>Kubernetes Federation</li>
</ul>
</li>
<li>商业模式<ul>
<li>云服务用户：避免使用单一云提供商导致的厂商锁定，避免技术和成本风险</li>
<li>云服务厂商：使用Kubernetes来打破AWS的先入垄断地位，抢夺市场份额</li>
</ul>
</li>
<li>Workload<ul>
<li>Pod<ul>
<li>Smalleset deployable computing unit</li>
<li>Consist of one or more containers</li>
<li>All containers in a pod share <a href="https://kubernetes.io/docs/concepts/storage/volumes/">storage</a>, <a href="https://zhaohuabing.com/post/2020-03-12-linux-network-virtualization/#network-namespace">network namespacem</a> and <a href="https://man7.org/linux/man-pages/man7/cgroups.7.html">cgroup</a></li>
</ul>
</li>
<li>Workload resources(Controllers)<ul>
<li>Deployment &amp; RelicaSet<ul>
<li>Deployment is used to deploy stateless appliations.</li>
<li>ReplicaSet ensured a specified numbers of pod replicas are running at a given time.</li>
<li>Deployment is used to rollout/update/rollback ReplicaSet.</li>
<li>ReplicaSet is not supposed to be used directly, it should be managed by Deployments.</li>
</ul>
</li>
<li>StatefulSet<ul>
<li>StatefulSet is used to deploy stateful applications.</li>
<li>SetatefSet require a Headless Service to provide network identity for the pods.</li>
</ul>
</li>
<li>DaemonSet<ul>
<li>DaemonSet ensures that all(or some) Nodes run a copy of a Pod.</li>
<li>Use cases: cluster storage daemon, logs collection daemon, node monitoring daemon.</li>
</ul>
</li>
<li>Job &amp; CronJob<ul>
<li>Job runs pods until a specified number of them have been succcessfully executed.</li>
<li>CronJob runs a job periodically on a given schedule.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Storage<ul>
<li>Volume<ul>
<li>purpose<ul>
<li>Persist data across the life span of a Pod<ul>
<li>Data won't lost when a container is restarted</li>
</ul>
</li>
<li>Share data between containers running together in a Pod<ul>
<li>Volume can be mounted to mutiple containers inside a Pod</li>
</ul>
</li>
</ul>
</li>
<li>type<ul>
<li>configMap</li>
<li>emptyDir</li>
<li>hostPath</li>
<li>local</li>
<li>persistentVolumeClaim</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Policies<ul>
<li>ResourceQuota<ul>
<li>purpose<ul>
<li>Limit the aggregated resource consumption of a Namespace</li>
</ul>
</li>
<li>Scope<ul>
<li>Namespaced: ResourceQuota is enforced in a Namespace scope, different Namespaces have different Resouce limit</li>
</ul>
</li>
<li>Type<ul>
<li>Compute Resource Quota<ul>
<li>CPU (limits.cpu requests.cpu)</li>
<li>Memory (limits.memory requets.memory)</li>
</ul>
</li>
<li>Storage Resource Quota<ul>
<li>Persistent Storage (storage)</li>
<li>Ephemeral Storage (ephermal-storage)</li>
</ul>
</li>
<li>Object Count Quota<ul>
<li>Limit of total number of Namespaced resources (count/services)</li>
</ul>
</li>
</ul>
</li>
<li>Request and Limit<ul>
<li>Request: Resources that are guaranteed to get</li>
<li>Limit: The maximum amount of resources that one can get</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Network<ul>
<li>Linux Network Virtualization<ul>
<li><a href="https://zhaohuabing.com/post/2020-02-24-linux-taptun/">Linux tun/tap</a></li>
</ul>
</li>
<li><a href="https://zhaohuabing.com/post/2020-03-12-linux-network-virtualization/#network-namespace">Network Namespace</a></li>
<li><a href="https://zhaohuabing.com/post/2020-03-12-linux-network-virtualization/#veth">Veth Pair</a></li>
<li><a href="https://zhaohuabing.com/post/2020-03-12-linux-network-virtualization/#bridge">Linux bridge</a><ul>
<li>Vlan</li>
<li>Vxlan</li>
<li><a href="https://cizixs.com/2017/09/25/vxlan-protocol-introduction/">Vxlan原理</a></li>
<li><a href="https://cizixs.com/2017/09/28/linux-vxlan/">Linux 上实现 vxlan 网络</a></li>
<li>Routing Protocol</li>
</ul>
</li>
<li>Distance Vector Protocol<ul>
<li>BGP</li>
</ul>
</li>
<li>Link-State Protocol<ul>
<li>OSPF<ul>
<li>K8s Network</li>
</ul>
</li>
</ul>
</li>
<li>Service<ul>
<li><a href="https://zhaohuabing.com/post/2019-03-29-how-to-choose-ingress-for-service-mesh/#cluster-ip">Cluster IP</a><ul>
<li>Provides access in the cluster internally</li>
<li>The ClusterIP range is defined in API server startup option <code>-service-cluster-ip-range</code></li>
<li>Service port is defined in the Service Manifest</li>
</ul>
</li>
<li><a href="https://zhaohuabing.com/post/2019-03-29-how-to-choose-ingress-for-service-mesh/#nodeport">NodePort</a><ul>
<li>Provides access at the node level</li>
<li>The NodePort range is defined in API server startup option <code>--service-node-port-range</code></li>
</ul>
</li>
<li><a href="https://zhaohuabing.com/post/2019-03-29-how-to-choose-ingress-for-service-mesh/#loadbalancer">LoadBalancer</a><ul>
<li>Provides an external IP to allow access from outside of the cluster</li>
</ul>
</li>
<li><a href="https://kubernetes.io/docs/concepts/services-networking/service/#externalname">ExternalName</a><ul>
<li>An alias to an external service</li>
<li>DNS redirection</li>
</ul>
</li>
<li><a href="https://zhaohuabing.com/post/2020-09-11-headless-mtls/#%E4%BB%80%E4%B9%88%E6%98%AF%E6%97%A0%E5%A4%B4%E6%9C%8D%E5%8A%A1">Headless</a><ul>
<li>Define a Headless service: specify "None" in for the cluster IP(.spec.clusterIP)</li>
<li>No cluster IP allocated to Headless services</li>
<li>No load balancing and proxying for Headless service</li>
<li>Kube dns returns the IP of the pods backing the service</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#proxy">Kube Proxy</a><ul>
<li>Provides a proxy server or appliction-level gateway between localhost and the K8s API server</li>
<li>Handles locating the apiserver and authenticating (uses cluster configuration and user credential in .kube/config)</li>
<li>Can send requests to API server (for example: get the list of services in default namespace <code>localhost:proxy-port/api/v1/namespaces/default/services</code>)</li>
<li>Can send requests to services via url <code>localhost:proxy-port/api/v1/namespaces/namespace_name/services/service_name[:port_name]/proxy/[application url]</code></li>
</ul>
</li>
<li>Kubectl port-forward<ul>
<li>Forward local ports to a pod</li>
<li>kebectl port-forward deployment/mydeployment localport:port</li>
<li>kebectl port-forward service/myservice localport:port</li>
<li>kebectl port-forward pod/mypod localport:port</li>
</ul>
</li>
<li>Ingress<ul>
<li><a href="https://zhaohuabing.com/post/2019-03-29-how-to-choose-ingress-for-service-mesh/#k8s-ingress">K8s Ingress</a></li>
<li><a href="https://zhaohuabing.com/post/2019-03-29-how-to-choose-ingress-for-service-mesh/#istio-gateway">Istio Ingress Gateway</a></li>
</ul>
</li>
<li>DNS<ul>
<li><a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#services">Service</a><ul>
<li>Normal Service<ul>
<li>A/AAA record which resolves name to the Cluster IP<ul>
<li>  - Name: <code>my-svc.my-namespace.svc.cluster-domain.example</code>
  - Example: <code>kubernetes.default.svc.cluster.local. 30 IN A   172.20.252.11</code></li>
</ul>
</li>
<li>SRV record for each named service port<ul>
<li>  - Name: <code>_my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster-domain.</code>example
  - Example: <code>_https._tcp.kubernetes.default.svc.cluster.local. 5 IN SRV 0 100 443 kubernetes.default.svc.cluster.local.</code></li>
</ul>
</li>
<li>A PTR record which resolves Cluster IP to domain name<ul>
<li>  - Example <code>1.252.20.172.in-addr.arpa. 5 IN  PTR kubernetes.default.svc.cluster.local.</code></li>
</ul>
</li>
</ul>
</li>
<li>Headless Service<ul>
<li>A/AAA record which resolves to the set of IPs of the pods selected by the service</li>
<li>N*M SRV records (N pods, M named ports in service)</li>
<li>A PTR record which resolves pod IP to domain name of each pod</li>
</ul>
</li>
<li>ExternalName<ul>
<li>A CNAME pointing to the domain name of the external service</li>
</ul>
</li>
</ul>
</li>
<li>Pod<ul>
<li>A/AAA record which resolves name to the pod IP</li>
<li>General name<ul>
<li>Name: <code>pod-ip-address.my-namespace.pod.cluster-domain.example</code></li>
<li>Example: <code>172-20-0-57.default.pod.cluster.local. 3 IN A   172.20.0.57</code></li>
</ul>
</li>
<li>Pod created by Deployment or DaemonSet exposed by a Service<h2>  - <code>pod-ip-address.deployment-name.my-namespace.svc.cluster-domain.example</code></h2>
</li>
</ul>
</li>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/#coredns">CoreDNS</a><ul>
<li>Plugins<ul>
<li>errors: Erros are logged to stdout</li>
<li>prometheus: Metrics of CoreDNS are available at <code>http://localhost:9153/metrics</code> in Prometheus format</li>
<li><a href="https://coredns.io/plugins/kubernetes/">kubernetes</a>: CoreDNS will reply to DNS queries based on IP of the services and pods of Kubernetes.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>腾讯云<ul>
<li><a href="https://zhaohuabing.com/post/2021-03-24-tke-network-mode/#global-router-%E6%A8%A1%E5%BC%8F">Global Router</a></li>
<li><a href="https://zhaohuabing.com/post/2021-03-24-tke-network-mode/#vpc-cni-%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F">VPC-CNI</a></li>
</ul>
</li>
<li><a href="https://zhaohuabing.com/post/2019-03-29-how-to-choose-ingress-for-service-mesh/#api-gateway--sidecar-proxy">API Gateway+Service Mesh</a></li>
<li>Kubernetes CNI插件<ul>
<li><a href="https://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2017/04/11/calico-usage.html">Calico</a></li>
</ul>
</li>
</ul>
</li>
<li>Scheduling<ul>
<li>Algorithm: Predicate find a set of available nodes -&gt; Priority select the best suitable node <ul>
<li>Predicates: find available nodes through some conditions: check memory, cpu, disk, etc.</li>
<li>Priorities: select a node to run the scheduled pod: select the node with the least amount of pods by default</li>
<li>Policy: specify a number of predicates and priorities</li>
</ul>
</li>
<li>Run a customscheduler<ul>
<li>Policy: <code>--policy-config-file</code></li>
<li>Name: <code>--scheduler-name</code></li>
</ul>
</li>
<li>Pod Specification: hits for pod scheduling<ul>
<li>NodeName: assign pods to the named node</li>
<li>NodeSelector: assign pods to a group of nodes with particular labels</li>
<li>Affinity and anti-affinity: <ul>
<li>Node<ul>
<li>Node affinity: has the same ability to constrain pods to particular nodes, but is more expressive and powerful</li>
<li>Node anti-affinity: use <code>NotIn</code> and <code>DoesNotExist</code> to achieve node anti-affinity</li>
</ul>
</li>
<li>Inter-Pod<ul>
<li>Inter-Pod affinity: co-locate some pods in the same nodes</li>
<li>Inter-Pod anti-affinity: distribute some pods in different nodes</li>
</ul>
</li>
</ul>
</li>
<li>taints and tolerations<ul>
<li>allow a node to repel a set of pods</li>
<li>allow pods to be scheduled onto nodes with matching taints</li>
</ul>
</li>
<li>SchedulerName: choose a specific scheduler to schedule a pod</li>
</ul>
</li>
</ul>
</li>
<li>Security<ul>
<li>Background Knowledge<ul>
<li><a href="https://zhaohuabing.com/post/2020-03-19-pki/">Certificate and PKI</a></li>
<li><a href="https://zhaohuabing.com/post/2020-05-19-k8s-certificate/">Kubernetes 中使用到的证书</a></li>
</ul>
</li>
<li>User Type<ul>
<li>Service Account<ul>
<li>Managed by Kubernetes</li>
<li>Represent workloads in the cluster</li>
<li>Bound to a specific namespace</li>
</ul>
</li>
<li><a href="https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/#normal-user">Normal User</a><ul>
<li>Managed out side of Kubernetes</li>
<li>Authenticated with a valid certicated signed by the cluster's CA<ul>
<li>User name: Certificate subject <a href="https://docs.oracle.com/cd/E24191_01/common/tutorials/authz_cert_attributes.html">Common Name</a> field</li>
<li>Group: Certificate subject <a href="https://docs.oracle.com/cd/E24191_01/common/tutorials/authz_cert_attributes.html">Organization</a> field</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Authentication<ul>
<li>Service account tokens for service accounts</li>
<li>Client certifications for normal users</li>
<li><a href="https://zhaohuabing.com/post/2020-05-19-k8s-certificate/#service-account--%E8%AF%81%E4%B9%A6">Certifications for control plane components communication</a></li>
<li><a href="https://zhaohuabing.com/post/2020-05-19-k8s-certificate/#%E4%BD%BF%E7%94%A8-tls-bootstrapping-%E7%AE%80%E5%8C%96-kubelet-%E8%AF%81%E4%B9%A6%E5%88%B6%E4%BD%9C">Bootstrap Token</a> for clusters and nodes bootstrapping</li>
</ul>
</li>
<li>Authorization<ul>
<li><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/">RBAC</a><ul>
<li>Namespace Scope<ul>
<li>Role</li>
<li>RoleBinding (Associate users retrived from authentication process to Roles)</li>
</ul>
</li>
<li>Cluster Scope<ul>
<li>ClusterRole</li>
<li>CluseterRoleBinding (Associate users retrived from authentication process to ClusteRoles)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Helm: package management tool for K8s applications<ul>
<li>Chart: package all k8s manifests as a single tarball<ul>
<li>Chart.yaml: this files contains metadata about this Chart: name, version, keywords</li>
<li>templeates: this directorey contains the resource manifests that makes up this application<ul>
<li>deployment</li>
<li>services</li>
<li>secretes</li>
<li>...</li>
</ul>
</li>
<li>values.yaml: this files contains keys and values that are used to generate the release. These values are replaced in the resource manifests using the Go template syntax</li>
</ul>
</li>
<li>Repository: HTTP servers that contains charts</li>
<li>Helm commands<ul>
<li>helm search hub redis: find redis chart and its repository in helm hub</li>
<li>helm sarch repo redis: find redis chart in repositories</li>
<li>helm install redis bitnami/redis: install redis chart</li>
</ul>
</li>
<li>Extending the Kubernetes API<ul>
<li>Custom Resource<ul>
<li>CRD: Define custom resources</li>
<li>Custom Resources/Ojbects: Declare the desired spec of a custom resource</li>
<li>Custom Controllers: watch-loop to make sure the actual state meet the declared spec</li>
</ul>
</li>
<li><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/">Aggregated API Server</a> <ul>
<li>Deploy an extension API server</li>
<li><a href="https://kubernetes.io/docs/tasks/extend-kubernetes/configure-aggregation-layer/">Register APIService objects</a><ul>
<li>Group: API groups this extension API server hosts</li>
<li>Version: API version this extension API server hosts</li>
</ul>
</li>
<li>kube-apiserver proxies client requests to the extension API server</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
