<h2><a href="https://github.com/conge/conge.github.io/blob/master/_posts/2019/2019-01-23-ML4T-03-02-Regression.md">仓库源文</a>，<a href="https://conge.livingwithfcs.org/2019/01/23/ML4T-03-02-Regression">站点原文</a></h2>
<ul>
<li>content
{:toc}</li>
</ul>
<h1>01 - Introduction</h1>
<p><img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-e5419ebca844dac9.png"/></p>
<p><strong>supervised regression learning</strong> or numerical model:</p>
<ul>
<li>using data to build a model that predicts a numerical output based on a set of numerical inputs.</li>
</ul>
<blockquote><p>Time: 00:00:23</p>
</blockquote>
<h1>02 - Parametric regression</h1>
<p>Parametric regression is a way of building a model where we represent the model with the number of parameters.
Example: build a model that will predict how much it will rain today based on changes in barometric pressure.</p>
<ul>
<li>if barometric pressure declines -&gt; bad weather or rain.</li>
<li>And when barometric pressure increases -&gt; good weather coming.</li>
</ul>
<p><img alt="" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-5e69f392e23a3a55.png"/></p>
<ul>
<li>each one of these dots represents one day's worth of data and we have multiple days worth of data here.</li>
<li>there's a general trend of as barometric pressure decreases, we typically have more rain and as it increases we have less rain.</li>
<li>The classic solution to this problem is to fit a line to the data. (linear regression).</li>
<li>The equation: y = m*x + b. which is a model fully described by two parameters m and b.</li>
<li>This model is decent, but it doesn't track the actual behavior of the data, for instance, </li>
</ul>
<p><img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-7af15c2f5d9c1da1.png"/></p>
<ul>
<li>we can fit a polynomial, by adding\ more term x&lt;sup&gt;2&lt;/sup&gt; and an additional parameter m2.</li>
<li>we can add more terms.</li>
</ul>
<p>All of these models are parametric models. In the end, after we learn these models and get our parameters (e.g. m2, m, and b), we can through away the data.</p>
<blockquote><p>Time: 00:04:12</p>
</blockquote>
<h1>03 - K nearest neighbor</h1>
<p><img alt="image.png" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-c4ebdf75824539c6.png"/></p>
<p><strong>Data-centric</strong> or <strong>instance based</strong> approach: keep and use the data  when we make a query.</p>
<ul>
<li>E.G. 3-NN and query here is at -5 millimeters. </li>
<li>we will find the 3 nearest historical data points to this query  and use them to estimate how much it's going to rain today</li>
</ul>
<blockquote><p>Time: 00:00:45</p>
</blockquote>
<h1>04 - Quiz: How to predict</h1>
<p>what should we do with these data points to find that prediction?</p>
<p><img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-296a41045648e3e6.png"/></p>
<ul>
<li>We don't want to take the largest y, because we want to take advantage of all these <strong>votes</strong> that we have to get a closer, more correct answer.</li>
</ul>
<blockquote><p>Time: 00:00:30</p>
</blockquote>
<h1>05 - Kernel regression</h1>
<p><img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-19e72eda00254162.png"/></p>
<ul>
<li>KNN will model the data like the red line, which fits the data where it's curving.</li>
<li>it interpolates nicely and smoothly between all the data points.</li>
<li>The most famous of these methods is K nearest neighbor.</li>
<li>kernel regression is another.<ul>
<li>The main way that KNN differs from kernel regression is that kernel regression weights the contributions of each of the nearest data points according to how distant they are.</li>
<li>Where as with KNN, each data point that we consider gets essentially an equal weight.</li>
</ul>
</li>
</ul>
<blockquote><p>Time: 00:01:32</p>
</blockquote>
<h1>06 - Parametric vs non-parametric</h1>
<p><img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-6161b51a41cdf634.png"/></p>
<ul>
<li>first problem: predicting cannonball distance with cannon aiming angle, </li>
<li>Second problem: predicting the number of bees a food source will attact given the richness of the food source.</li>
</ul>
<blockquote><p>the cannon ball distance can be best estimated using a parametric model, as it follows a well-defined trajectory.
On the other hand, the behavior of honey bees can be hard to model mathematically. Therefore, a non-parametric approach would be more suitable.
<img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-6d0126cf6c91d05e.png"/></p>
</blockquote>
<ul>
<li>the cannonball model is <strong>biased</strong>, in the sense that we have an initial guess of what the form of the equation is.</li>
<li>the bee model is <strong>unbiased</strong> because we don't know.</li>
</ul>
<p><strong> the pros and cons of each approach</strong>.</p>
<ol>
<li><strong>parametric approach</strong>: </li>
</ol>
<ul>
<li>we don't have to store the original data, so it's very space efficient, </li>
<li>but we can't easily update the model as more data is gathered.</li>
<li>training is slow</li>
</ul>
<ol>
<li><strong>non-parametric approaches, or instance-based</strong>: have to store all the data points.</li>
</ol>
<ul>
<li>hard to apply when we have a huge data set,</li>
<li>but new evidence can be added easily s</li>
<li>training is fast, but querying is potentially slow.</li>
<li>nonparametric approaches avoid having to assume a certain type of model so they're suitable to fit complex patterns</li>
</ul>
<blockquote><p>Time: 00:02:47</p>
</blockquote>
<h1>07 - Training and testing</h1>
<p><img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-c3139559901d7898.png"/></p>
<ul>
<li>X data: X1, X2, X3, and so on.</li>
<li>Y data, which we're trying to predict.</li>
<li>In order to evaluate our learning algorithms in a scientific manner we need to split this data into at least two sections. A training section and a testing section.</li>
</ul>
<p><strong>out of sample testing</strong>: The procedure of separating testing and training data from one another.</p>
<ul>
<li>take our Xtrain data and our Ytrain data, run that through our machine learning algorithm to generate a model.</li>
<li>Then test the accuracy of that model using Xtest and Ytest data.<ul>
<li>the input to the model is Xtest, and the model gives back Y-predict.</li>
<li>compare Y-predict data with Ytest data,the more closely the model outputs a Y that reflects this Xtest data, the more accurate the model is.</li>
</ul>
</li>
</ul>
<p><strong>in this class, our data is time oriented</strong>, and we typically split the data up according to time.</p>
<ul>
<li>train model on older data and test it on newer data.</li>
<li>doing the reverse will have certain look-ahead biases.</li>
</ul>
<blockquote><p>Time: 00:02:50</p>
</blockquote>
<h1>08 - Learning APIs</h1>
<p><img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-5588c5bdedb4fb9c.png"/></p>
<p>When write some machine learning algorithms in the class, let's standardize on what the application programmer interface ought to look like for the code.</p>
<ul>
<li>the learner should have a train method and a query method.</li>
</ul>
<p>linearregression Learner.
KNNLearner: additional argument, K</p>
<blockquote><p>Time: 00:01:14</p>
</blockquote>
<h1>09 - Example for linear regression</h1>
<p><img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-1448960f56a30f5c.png"/></p>
<p>pseudo code for implementing the API for a linear regression learner.</p>
<blockquote><p>Time: 00:02:13</p>
<p>Total Time: 00:18:55</p>
</blockquote>
<pre><code>2019-01-23 09:13:42
</code></pre>
