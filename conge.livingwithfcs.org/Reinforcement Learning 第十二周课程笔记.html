<h2><a href="https://github.com/conge/conge.github.io/blob/master/_posts/2015/2015-11-04-Reinforcement-Learning--di-shi-er-zhou-ke-cheng-bi-ji-.md">仓库源文</a>，<a href="https://conge.livingwithfcs.org/2015/11/04/Reinforcement-Learning--di-shi-er-zhou-ke-cheng-bi-ji-">站点原文</a></h2>
<hr/>
<h2>layout: post
title: "Reinforcement Learning 第十二周课程笔记"
date: "2015-11-04 11:01:52"
categories: 计算机科学
excerpt: "This week watch Game Theory. The readings are Littman (1994), Littman an..."
auth: conge</h2>
<ul>
<li>content
{:toc}</li>
</ul>
<p>This week</p>
<ul>
<li>watch <em>Game Theory.</em> </li>
<li>The readings are <em>Littman (1994), Littman and Stone (2003),</em> <em>Greenwald and Hall (2003)</em>, <em>Munoz de Cote *and *Littman (2008).</em></li>
<li>Assignment 10 is up.</li>
</ul>
<p><img alt="Game Theory III" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-9b254b5b7180567a.png"/></p>
<p><img alt="Definition of Game Theory" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-8179a16827ff6419.png"/></p>
<ul>
<li>Game theory is mathematics of conflict of interests.</li>
<li>It generalizes the RL from single agent to multiple agents.</li>
<li>It is of the interest of economics, politics, sociology or even biology since these fields often deal with agents with many many agents with conflicts of interests.</li>
</ul>
<h2>Example</h2>
<p><img alt="Quiz 1: simple game example" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-c525e118b091d2fa.png"/></p>
<ul>
<li>The example game is represented as a tree, nodes are states, edges are transitions and leafs are rewards.</li>
<li>the example game has 2 agent  (<em>a</em> and <em>b</em>), all the rewards added up to be a constant ( zero-sum), no stochastic transitions. The leafs show the reward that agent <em>a</em> can get and <em>b</em> gets (-1 * reward).</li>
<li>Strategies: what action should the agent take at each state it could be in. (equivalent to policy in RL)</li>
<li><strong>The agents are assumed to be rational</strong>.</li>
</ul>
<p><img alt="Quiz 2: Represent the tree using a matix" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-bc72bd67a07404a9.png"/></p>
<ul>
<li>this is a simple example of 2-agent zero-sum game<ul>
<li>zero-sum means the reward of A and B will sum to 0 for any strategy.</li>
</ul>
</li>
<li>A matrix is enough to represent a game.</li>
<li>once the matrix is here, the tree doesn't matter now.</li>
<li>need to learn to generate the matrix from the tree.</li>
</ul>
<h3>Minimax</h3>
<p><img alt="MiniMax" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-f09694462ec01c5d.png"/></p>
<ul>
<li>A and B has the same goal, maximize their own reward ( and minimize others reward).</li>
<li>If A and B behave rationally, they will reach the same strategy.</li>
</ul>
<p><img alt="Von Neumann theorem" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-988f9efa92a72c7f.png"/></p>
<p>This is important so I am writing it down:</p>
<ul>
<li>In a 2-agent, zero-sum, deterministic game of perfect information, Minimax ≡ Maximin,</li>
<li>and there always exist an <strong>optimal pure strategy</strong> for each agent.</li>
<li>Based on the strategy matrix, one can always build at least one tree.</li>
</ul>
<p>Now, to make the problem a bit more complex, we change the game to be non-deterministic:</p>
<p><img alt="quiz 3: strategy matrix for non-deterministic game" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-50c6fbb3c28d9c12.png"/></p>
<ul>
<li>Introduce the <strong>chance box</strong>, so that transition is non-deterministic.</li>
<li>construct the strategy matrix based on tree ( but could not reconstruct tree based on matrix)<ul>
<li>note: from the matrix, we don't know if the tree is deterministic or not.</li>
</ul>
</li>
<li>the minimax theorem (Von Neumann theorem) still holds<ul>
<li>Minimax ≡ Maximin</li>
<li>Optimal pure strategy exists.</li>
</ul>
</li>
</ul>
<h3>Minipoker</h3>
<p><img alt="Mini-Poker: description" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-9cd1c457cf0b0b85.png"/></p>
<p><img alt="Mini-Poker: Tree and Matrix" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-5f3f27c2ca021e58.png"/></p>
<ul>
<li>In the minipoker game, b will not know all the information, so it's a 2-agent, zero-sum, non-deterministic game of <strong>hidden</strong> information</li>
<li>In this case, Minimax ≠ Maximin and there will be no optimal pure strategy.</li>
<li>but there will be mixed Strategy, which is a distribution of strategies.</li>
</ul>
<h3>Mixed Strategy</h3>
<p><img alt="Quiz 5: Given B's strategy, we can figure out A's expected profit" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-0bc6ece04f4063ec.png"/></p>
<ul>
<li>A's expected strategy are linear equation, which can be represented by lines.</li>
</ul>
<p><img alt="Quiz 6: A's expected value is dependent on B" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-f9aff2e241589354.png"/></p>
<ul>
<li>the mixed strategy should be at the intercept of the two lines in this case.</li>
<li>if the two lines both have positive slope, the mixed strategy should be at the far right; if negative slope, the strategy should be at the far left.</li>
<li>the expected value of the game is deterministic still.</li>
<li>although the strategy is mixed, there is still an expected value, in this case, the expected value is when p is 0.4, and value is <strong>1</strong>.</li>
</ul>
<h3>Snitch</h3>
<p><img alt="Prisonders' Dilemma" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-0e0fe0d8c2a33ba9.png"/></p>
<ul>
<li>Now, we are making the game non-zero-sum.</li>
<li>The prisoner's dilemma is a 2-agent, <strong>non-zero-sum</strong>, non-deterministic game of <strong>hidden</strong> information</li>
<li>Assume the agents are rational, both of them should defect.</li>
</ul>
<h2>A Beautiful Equilibrium</h2>
<p><img alt="Nash Equilibrium" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-c64a9d2c87418480.png"/></p>
<ul>
<li>in practice, if we are in a Nash Equilibrium, any agent will have no good reason to change strategy ( pure or mixed).</li>
</ul>
<p><img alt="Theorem" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-366db8dc4353b059.png"/></p>
<ul>
<li>in the n-player pure strategy game, if elimination of strictly dominated strategies eliminates all but one combination, that combination is the unique NE.</li>
<li>Any N.E. will survive elimination of strictly dominated strategies</li>
<li>if n is finite, for each set of finite strategies, then there will be at least one strategy is N.E.</li>
</ul>
<p><img alt="Play the game multiple times: won't change NE" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-4aa471fa4c640944.png"/></p>
<ul>
<li>what if playing the game multiple times?</li>
<li>only the last game matters-&gt; the last game will be N.E -&gt; since the last game is known now, the last game moves to the game before it.-&gt; the last game will be N.E. -&gt; repeat.... -&gt;all the game should will be N.E.</li>
</ul>
<h2>Recap</h2>
<p><img alt="Recap" src="/media/wwww/share/study/聚聚/源数据/博客聚合/conge.livingwithfcs.org/assets/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/118382-fe3248dded8f62ec.png"/></p>
<p><a href="http://www.autonlab.org/tutorials/gametheory.html">Andrew Moore's slides on Zero-Sum Games</a>
<a href="http://www.autonlab.org/tutorials/nonzerosum.html">Andrew Moore's slides on Non-Zero-Sum Games</a></p>
<pre><code>2015-11-03 初稿
2016-04-26 复习并添加部分内容
</code></pre>
