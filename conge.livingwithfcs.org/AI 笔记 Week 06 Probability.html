<h2><a href="https://github.com/conge/conge.github.io/blob/master/_posts/2017/2017-10-12-AI--bi-ji--Week-06-Probability.md">仓库源文</a>，<a href="https://conge.livingwithfcs.org/2017/10/12/AI--bi-ji--Week-06-Probability">站点原文</a></h2>
<hr/>
<p>layout: post
title: "AI 笔记 Week 06 Probability"
date: "2017-10-12 02:24:06"
categories: 计算机科学
excerpt: "Week 6 Announcement This week you should watch Lesson 5, Probability, an..."</p>
<h2>auth: conge</h2>
<ul>
<li>content
{:toc}</li>
</ul>
<p><strong>Week 6 Announcement</strong></p>
<blockquote><p>This week you should watch Lesson 5, <a href="https://www.udacity.com/course/viewer#!/c-ud954/l-6385118556">Probability</a>, and read Chapter 13 in AIMA (Russell &amp; Norvig).
Assignment 3:  Bayes Nets Sampling</p>
</blockquote>
<h1>Challenge question</h1>
<p><img alt="chanllenge question" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-bdd581be592c90cf.png"/></p>
<p><img alt="Solution" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-b95fbf265cace06f.png"/></p>
<p><img alt="Solution" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-1217680c12f9222b.png"/></p>
<ul>
<li>P(x) is the probability of the disease without other constraints</li>
<li>P(Y) is calculated P(Y| ~X)P(~X) + P(Y|X)P(X)</li>
</ul>
<h1>Intro To Probability And Bayes Nets</h1>
<p><img alt="Bayes network example" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-a6ffea0d2051c208.png"/></p>
<ul>
<li>in the above example, we have random variables represents events which are connected by arrows to describe the relationships.</li>
<li>the arrows indicate that the child nodes are influenced by their parents, and the influence can be a deterministic or probabilistic way.</li>
<li><strong>Bayes net is a compact representation of the distribution of the large probability distribution of all the variables</strong>.</li>
<li>With Bayes net, we can <em>specify</em> the distribution, <em>observe</em> certain variables and <em>compute</em> probabilities of unobserved variables.</li>
</ul>
<h2>outline</h2>
<p><img alt="outline" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-a9ebad4988c97484.png"/></p>
<h1>Probability / Coin Flip</h1>
<p><img alt="Probability" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-f95b8610e7d2877c.png"/></p>
<ul>
<li>P(T) = 1 - P(H)</li>
<li>since H and T are <strong>independent</strong> events, P(H,H,H) = P(H) x P(H) x P(H) </li>
</ul>
<p><img alt="Probability 2" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-d23e09d4a1b93018.png"/></p>
<ul>
<li>remember, P(H) and P(T) are independent</li>
</ul>
<h2>Summary</h2>
<p><img alt="Complementary and independence" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-314c1b2bd63f4715.png"/></p>
<h1>Dependence</h1>
<p><img alt="Dependence" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-f8728423729c5b6b.png"/></p>
<p><img alt="" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-4f484b1880b69f47.png"/></p>
<h1>quiz: Weather</h1>
<p><img alt="quiz" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-062107c02e5afa59.png"/></p>
<ul>
<li>complementary rule applies for the first 2 quiz questions.</li>
</ul>
<p><img alt="quiz" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-8db3032fff45cb3a.png"/></p>
<ul>
<li>dependence rule applies to the calculation of P(D2 = Sunny) and P(D3 = Sunny)</li>
<li>P(D2 = Sunny) = P(D2 = Sunny | D1 = Sunny) x P(D1 = Sunny) + P(D2 = Sunny | D1 = Rainy) x P(D1 = Rainy) </li>
<li>Simillarly, * P(D3 = Sunny) = P(D3 = Sunny | D2 = Sunny) x P(D2 = Sunny) + P(D3 = Sunny | D2 = Rainy) x P(D2 = Rainy) </li>
</ul>
<h2>Quiz: Cancer</h2>
<p><img alt="joint probability" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-ec2a14fcb5e1abf4.png"/></p>
<ul>
<li>joint probability of a and b is P(a, b) = P(a) x P(b)</li>
</ul>
<p><img alt="" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-3049aa872c2cfa90.png"/></p>
<ul>
<li>P(C | +) = P( +,C) /(P(+,C) + P(-,C))</li>
<li>this is the Bayes rule!</li>
</ul>
<h1>Bayes Rule</h1>
<p><img alt="Bayes Rule" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-da772d3644cb4754.png"/></p>
<ul>
<li>Prior</li>
<li>Posterior</li>
<li>Likelihood</li>
<li>Marginal likelihood (Total probability)</li>
</ul>
<pre><code>20171006 初稿
</code></pre>
