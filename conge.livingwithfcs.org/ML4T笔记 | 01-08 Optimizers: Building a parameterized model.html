<h2><a href="https://github.com/conge/conge.github.io/blob/master/_posts/2018/2018-01-15-ML4T-01-08-Optimizers--Building-a-parameterized-model.md">仓库源文</a>，<a href="https://conge.livingwithfcs.org/2018/01/15/ML4T-01-08-Optimizers--Building-a-parameterized-model">站点原文</a></h2>
<hr/>
<p>layout: post
title: "ML4T笔记 | 01-08 Optimizers: Building a parameterized model"
date: "2018-01-15 01:15:15"
categories: 计算机科学
auth: conge</p>
<h2>tags: Machine_Learning Trading ML4T OMSCS</h2>
<ul>
<li>content
{:toc}</li>
</ul>
<h1>01 - What is an optimizer</h1>
<p><img alt="image.png" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-181de1a70f03c0fd.png"/></p>
<p><strong>What is an optimizer?</strong>: An optimizer is an algorithm that can:</p>
<ul>
<li>find minimum values for functions.</li>
<li>find the parameters for parameterized models from data.  </li>
<li>find a polynomial fit to that data.</li>
<li>refine allocations to stocks in portfolios (e.g. what percentage of funds should be allocated to each stock).</li>
</ul>
<p><strong>How do we use an optimizer?</strong> three key steps.</p>
<p><img alt="" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-f089ed302991596e.png"/></p>
<ol>
<li>define a function that you want to minimize.
define in Python and then the minimizer will call this function many, many times as it tries to find the minimum values for x that causes this function overall to be smallest.</li>
<li>Choose an initial guess for x (might be close to the solution to the problem or choose a random value, or just some standard value).</li>
<li>call the optimizer starts with that guess and it repeatedly calls a function, tests different values, and narrows in on the solution.</li>
</ol>
<blockquote><p>Time: 00:02:30</p>
</blockquote>
<h1>02 - Minimization example</h1>
<p><img alt="" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-885fb6587483b1ce.png"/></p>
<ul>
<li><p>example: f(x) = (x - 1.5)&lt;sup&gt;2&lt;/sup&gt; + 0.5. The function is centered horizontally at 1.5, and its minima is here at 0.5.</p>
</li>
<li><p>for example, the optimizer start with a guess of 2.0.</p>
</li>
<li>The first thing it does is it checks the value at 2.0, it turns out that that's about 0.75. then tests the value nearby and finds out that this equation's slope</li>
<li>Now, it's trying to minimize, and it marches downhill, it's called <strong>gradient descent</strong></li>
<li>Eventually, it narrows and it discovers that 1.5 is the value for x at the minima and the value of y there is 0.5.</li>
<li>And SciPy, the library that we're using, has many of those options.</li>
</ul>
<blockquote><p>Time: 00:02:10</p>
</blockquote>
<h1>03 - Minimizer in Python</h1>
<p><img alt="Python code" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-d188f388b4cb6fe3.png"/></p>
<ul>
<li>Function to minimize <code>Y= (X-1.5)**2 +0.5</code>.</li>
<li><code>import scipy.ptimizer as spo</code> </li>
<li><code>spo.minimize(f,Xguess, method='SLSQP', options={'disp': True})</code> call the optimizer or the minimizer by setting the guess value to be 2.0. <ul>
<li><strong>F</strong> is the function here, so we're saying minimizer,</li>
<li>Method is the minimizing algorithm.</li>
<li><strong>disp</strong> is True, which means "verbose about things that it discovers".</li>
</ul>
</li>
<li>The minimizer repeatedly calls our function and finds the minimum value</li>
</ul>
<p>Let's try a test run and see what happens.</p>
<p><img alt="Output" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-639a5a60374a4035.png"/></p>
<ul>
<li>the minimizer is repeatedly calling that function f and it's printing these things out.</li>
<li>When <code>X = 2</code> and it discovers that the value is <em>0.75</em>.</li>
<li>Then a value slightly greater than 2, a value slightly less than 2.</li>
<li>And the minimizer very quickly converges on 1.5 as the answer with a value of 0.5 .</li>
</ul>
<blockquote><p>Time: 00:03:25</p>
</blockquote>
<h1>04 - Quiz: How to defeat a minimizer</h1>
<p>Given the four function shapes to look at, which one(s) is harder to sovle and why?</p>
<p><img alt="" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-e843049552286547.png"/></p>
<p>Note: these are solvable by optimizers, but just hard. In fact, there are optimizers that can solve these problems with varying degrees of success. but sucess is not guareentted.</p>
<blockquote><p>Time: 00:01:30</p>
</blockquote>
<h1>05 - Convex problems</h1>
<p><img alt="image.png" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-72f8e3610398785d.png"/></p>
<p>Minimizer are especially good at solving <strong>convex problems</strong>.</p>
<p>The formal definition of a convex function.</p>
<blockquote><p>A real valued function <em>f(x)</em> defined on an interval is called convex if the line segment between any two points on the graph of the function lies above the graph.</p>
</blockquote>
<p>To tell if a function is vonvex:</p>
<ol>
<li>choose two points and draw a line between them.</li>
<li>for each of these lines, if the line is above the graph, everywhere between those two points, then the function is convex between those points.</li>
</ol>
<ul>
<li>In order for the function to be convex, 1) it has to have only one local minima.2) it can't have any flat regions that essentially don't have any slope downward.</li>
<li>Non-convex problems might be solvable they require a little bit of randomness and they aren't necessarily guaranteed to find the global minima.</li>
</ul>
<blockquote><p>Time: 00:03:10</p>
</blockquote>
<h1>6 - Building a parameterized model</h1>
<p><img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-30d03a0d9e6aa82e.png"/></p>
<ul>
<li><p>parameterized model, for example, used parameters to represent slop and intercept in a function f(x) = C&lt;sub&gt;0&lt;/sub&gt;x + C&lt;sub&gt;1&lt;/sub&gt;. C&lt;sub&gt;0&lt;/sub&gt; and C&lt;sub&gt;1&lt;/sub&gt; are parameters of the linear model.</p>
</li>
<li><p>Suppose we have a data set represented by the green dots, if we fit the data by a line, it looks like the line will have is C&lt;sub&gt;0&lt;/sub&gt; equivalent to the slope here, and  C&lt;sub&gt;1&lt;/sub&gt; is the y intercept.</p>
</li>
<li><p>Suppose this blue line is a candidate line and we want to evaluate it. Is this good or bad?</p>
<ul>
<li>a minimizer can vary C&lt;sub&gt;0&lt;/sub&gt; and C&lt;sub&gt;1&lt;/sub&gt; to try and minimize something to come up with an equation that gets lower in value as this line better fits the data.</li>
</ul>
</li>
</ul>
<p>What should we use for that equation?</p>
<p><img alt="" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-585027ffeff0eca0.png"/></p>
<ul>
<li>error: each one of our original data points and observe how far away it is from this line that we're evaluating.</li>
</ul>
<blockquote><p>Time: 00:03:31</p>
</blockquote>
<h1>07 - quiz What is a good error metric</h1>
<p><strong> which of these formulae might be a good overall error measure?</strong></p>
<p><img alt="My answer" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-1869419ff8f4bf43.png"/></p>
<blockquote><p>Simply summing up the errors doesn't work, as some of them may be negative.
Taking the absolute value or squared error solves that problem.</p>
</blockquote>
<h1>08 - Minimizer finds coefficients</h1>
<p><img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-cfea637f6337e21a.png"/></p>
<p>Steps of a minimizer finding the coefficients of a line that best fits this data. (we need to give the minimizer an equation that it has to minimize).</p>
<ul>
<li>the function to minimize is the error metric function, in this case, the squared error.</li>
</ul>
<ol>
<li>guess an initial C&lt;sub&gt;0&lt;/sub&gt; and C&lt;sub&gt;1&lt;/sub&gt; and that would be a line like this, and we would give that to the minimizer and let it go.</li>
<li>the minimizer would measure the error with this particular line, it would fiddle with these values a little bit and see how much the error changed, try a new set of values see how that works.</li>
<li>it's going to iterate, and eventually settle on what it thinks is the best solution.</li>
</ol>
<ul>
<li>key points here are that we express the problem for the minimizer as a minimization problem and we give it the equation to minimize as the error.</li>
</ul>
<blockquote><p>Time: 00:01:16</p>
</blockquote>
<h1>09 - Fit a line to given data points</h1>
<p><img alt="" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-f89692e908182827.png"/></p>
<ul>
<li>in the  <code>test_run()</code> function, we plot the original line (ln 45~50), add some noise to the data (ln 52~ 36) and fit the line with the the <code>fit_line(data, error)</code> function and <code>data</code> and <code>error</code> function as input.</li>
<li>the <code>error()</code> function and the <code>fit_line()</code> are defined by the code below.</li>
</ul>
<p><img alt="Define error function" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-34b37a7032e3c560.png"/></p>
<ul>
<li>function <code>error()</code>, and it takes two parameters, line and data. Line is just the two coefficients, C&lt;sub&gt;0&lt;/sub&gt; and C&lt;sub&gt;1&lt;/sub&gt;. And data is just a list of data</li>
<li>ln20: <code>err</code> is the squared error which is the squred difference between the data and the estimated data by the line.</li>
</ul>
<p><img alt="Fit_line()" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-dace63a6a8ab7159.png"/></p>
<ul>
<li>ln 34 is the inital value for the linear model. here we set the splot to be 0 and the Y-intercept is the mean of the y value of all the datapoints.</li>
<li>ln 37 is the range of X </li>
<li>ln 41 calls the minimizer, give it the <code>error_fun</code>c, ininital guess <code>l</code>. <code>args=(data,)</code> passes the data into the error function.</li>
</ul>
<p><img alt="output" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-5298b93d7e2de2a6.png"/></p>
<ul>
<li>Our original line is this blue line.</li>
<li>These green dots are our noisy data where we just added noise values to the blue line.</li>
<li>What we did were<ul>
<li>asking our optimizer to find the equation of a line that best fits this data.</li>
<li>The metric we are trying to minimize is error.</li>
<li>we passed it in an initial guess (purple line) and the noisy data.</li>
</ul>
</li>
<li>the minimizer iterates and tries different slopes and different y intercepts. Until finally, it converges to the red line and that's the solution.</li>
</ul>
<blockquote><p>Time: 00:05:51</p>
</blockquote>
<h1>10 - And it works for polynomials too</h1>
<p>We can fit even more complicated functions to data like this.
<img alt="" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-19f70fb7d60bd8ab.png"/></p>
<p>Our original polynomial is <em>f(x)</em> = 1.5x&lt;sup&gt;4&lt;/sup&gt; - 10x &lt;sup&gt;3&lt;/sup&gt; - 5 x&lt;sup&gt;2&lt;/sup&gt;+ 60x + 50.</p>
<p>Let's look now at how we do that in code.</p>
<p><img alt="error function" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-0b2ac420504c17b3.png"/></p>
<ul>
<li>a higher-degree polynomial is very similar to what we had for the line.</li>
<li>take in the coefficients for the polynomial and the actual data.</li>
<li>ln 20 is the error function, it's a sum of the difference between the actual data and the polynomial value squared and we take the sum of all those values as error metric.</li>
</ul>
<p>Here's our function that finds the coefficients of the polynomial has just a few parameters.
<img alt="" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-24dd901c5f4b9a52.png"/></p>
<ul>
<li>the <code>fit_poly()</code> function will take the data and trying to fit our error function. And the degree of the polynomial.</li>
<li>ln 35: We created an initial guess. setting them all to be ones.</li>
<li>ln 38~39:  plot that, </li>
<li>line 42:we call our minimizer.</li>
</ul>
<p>And that's it that's how we use Python to create a model based on data.</p>
<blockquote><p>Time: 00:03:07</p>
</blockquote>
<h1>13 - Wrapping up optimizers</h1>
<p><img alt=" " src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/conge.livingwithfcs.org/assets/images/计算机科学/118382-efa56870b3fdbc39.png"/></p>
<p>Recap: We have learned</p>
<ul>
<li>how to use a minimizer to find x such that f of x is minimized.</li>
<li>how to minimize in multiple dimensions.</li>
<li>how to use a minimizer to build a parametrized model.</li>
</ul>
<p>Where can you go from here?.</p>
<ul>
<li>You can use functions besides polynomials, you can model stock prices, or you can optimize a portfolio.</li>
</ul>
<blockquote><p>Time: 00:00:27</p>
<p>Total Time: 00:28:37</p>
</blockquote>
<pre><code>2018-01-15 初稿
</code></pre>
