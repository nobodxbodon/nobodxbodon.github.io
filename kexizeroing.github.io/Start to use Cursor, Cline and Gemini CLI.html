<h2><a href="https://github.com/kexizeroing/kexizeroing.github.io/blob/master/src/blog/start-to-use-cursor-and-cline.md">仓库源文</a>，<a href="https://kexizeroing.github.io/start-to-use-cursor-and-cline">站点原文</a></h2>
<h2>Cursor Get Started</h2>
<p>Migrate VS Code settings:</p>
<ol>
<li><code>Cmd + Shift + P</code> and type Cursor Settings (or <code>Cmd + Shift + J</code> to open Cursor settings)</li>
<li>Navigate to General &gt; Account</li>
<li>Under “VS Code Import”, click the Import button</li>
</ol>
<p>This will transfer your Extensions, Themes, Settings, Keybindings. You can see all keyboard shortcuts by pressing <code>Cmd + R</code> then <code>Cmd + S</code>.</p>
<p>We made Activity Bar Orientation horizontal by default. If you prefer vertical:</p>
<ol>
<li><code>Cmd + Shift + P</code> -&gt; Preferences: Open Settings (UI)</li>
<li>Search for <code>workbench.activityBar.orientation</code> and set it to <code>vertical</code></li>
</ol>
<p>Start exploring Cursor’s AI-powered features:</p>
<ul>
<li>Tab: Press <code>Tab</code> for intelligent code completions</li>
<li>CMD-K: Use <code>Cmd + K</code> for inline code edits</li>
<li>Chat: Use <code>Cmd + I</code> to open the unified AI interface with Ask, Edit, and Agent modes
​
Cursor lets you input your own API keys for various LLM providers to send as many AI messages as you want at your own cost. To use your own API key, go to Cursor Settings &gt; Models and enter your API keys.</li>
</ul>
<p>To view your current usage, you can visit the dashboard at <a href="https://www.cursor.com/dashboard">cursor.com/dashboard</a></p>
<h3>Tab</h3>
<p>Cursor Tab is our native autocomplete feature. You can accept a suggestion by pressing <code>Tab</code>, or reject it by pressing <code>Esc</code>.</p>
<h3>Chat (Cmd + I)</h3>
<p>Chat (previously “Composer”) is Cursor’s AI assistant that lives in your sidebar, letting you interact with your codebase through natural language.</p>
<p>Sometimes you may want to revert to a previous state of your codebase. Cursor helps you with this by automatically creating checkpoints of your codebase at each request you make, as well every time the AI makes changes to your codebase. To revert to a previous state, you can click the “Restore Checkpoint” button that appears within the input box of a previous request.</p>
<p>Agent is the default and most autonomous mode in Cursor, designed to handle complex coding tasks with minimal guidance. It has all tools enabled to autonomously explore your codebase, read documentation, browse the web, edit files, and run terminal commands to complete tasks efficiently.</p>
<p>Ask is a “read-only” mode for the Chat made to ask questions, explore, and learn about a codebase. It is a built-in mode in Cursor that has search tools enabled by default.</p>
<p>Manual mode is designed for making targeted code modifications when you know exactly what changes are needed and where. To make use of Manual mode, you need to explicitly mention the files you want to edit using the <code>@</code> symbol. <em>e.g. “In @src/utils/helpers.ts and @src/components/UserProfile.tsx, rename the function <code>getUserData</code> to <code>fetchUserProfile</code> and update all call sites within these files.”</em></p>
<h3>Inline Edit (Cmd + K)</h3>
<p>We call the bar that appears when you press <code>Cmd + K</code> the “Prompt Bar”. It works similarly to the AI input box for chat, in which you can type normally, or use <code>@</code> symbols to reference other context.</p>
<p>If no code is selected when you press <code>Cmd + K</code>, Cursor will generate new code based on the prompt you type in the prompt bar. For in-place edits, you can simply select the code you want to edit and type into the prompt bar.</p>
<p>When your changes might affect multiple files or you need more advanced capabilities, use <code>Cmd + L</code> to send your selected code to the Agent. This seamlessly transitions your work to Chat mode.</p>
<h3>Context</h3>
<p>When a project is opened, each Cursor instance will initialize indexing for that workspace. After the initial indexing setup is complete, Cursor will automatically index any new files added to your workspace to keep your codebase context current. Behind the scenes, Cursor computes embeddings for each file in your codebase, and will use these to improve the accuracy of your codebase answers.</p>
<p>The status of your codebase indexing is under Cursor Settings &gt; Features &gt; Codebase Indexing.</p>
<p>You can control which directories and files Cursor can access by adding a <code>.cursorignore</code> file to your root directory. Cursor makes its best effort to block access to files listed in <code>.cursorignore</code> from codebase indexing, Tab, Chat, Cmd-K, and <code>@</code> symbol references.</p>
<p>In Cursors input boxes, you can use <code>@</code> symbols by typing <code>@</code>. A popup menu will appear with a list of suggestions, and it will automatically filter to only show the most relevant suggestions based on your input.</p>
<h3>Rules</h3>
<p>LLMs do not retain memory between completions. Rules solve this by providing persistent, reusable context at the prompt level. When a rule is applied, its contents are included at the start of the model context. Rules apply to both <code>Chat</code> and <code>Cmd-K</code>.</p>
<p>Project rules live in <code>.cursor/rules</code>. Each rule is stored as a file and version-controlled. Each rule file is written in MDC (<code>.mdc</code>), a lightweight format that supports metadata and content in a single file.</p>
<pre><code class="lang-mdc">---
description: xxx
globs: **/**
---

...content goes here...
</code></pre>
<p>You can use <code>Cmd + Shift + P</code> &gt; “New Cursor Rule” to create a rule quickly from inside Cursor. This will create a new rule file in the <code>.cursor/rules</code> directory. You can also generate rules directly in a conversation using the <code>/Generate Cursor Rules</code> command.</p>
<blockquote><p>The <code>.cursorrules</code> file in the root of your project is still supported, but will be deprecated. We recommend migrating to the Project Rules format for more control, flexibility, and visibility.</p>
</blockquote>
<p>You can organize rules by placing them in <code>.cursor/rules</code> directories throughout your project structure. For example:</p>
<pre><code>project/
  .cursor/rules/    # Project-wide rules
  backend/
    .cursor/rules/  # Backend-specific rules
  frontend/
    .cursor/rules/  # Frontend-specific rules
</code></pre>
<p>Nested rules automatically attached when files in their directory are referenced. This is particularly useful in monorepos or projects with distinct components that need their own specific guidance.</p>
<ul>
<li><a href="https://github.com/PatrickJS/awesome-cursorrules">https://github.com/PatrickJS/awesome-cursorrules</a></li>
<li><a href="https://cursorlist.com">https://cursorlist.com</a></li>
<li><a href="https://cursor.directory">https://cursor.directory</a></li>
</ul>
<h3>MCP</h3>
<p>Think of MCP as a plugin system for Cursor - it allows you to extend the Agent’s capabilities by connecting it to various data sources and tools through standardized interfaces.</p>
<p>Cursor supports two transport types for MCP servers:</p>
<ul>
<li>For stdio servers, the command should be a valid shell command that Cursor can run.</li>
<li>For SSE servers, the URL should be the URL of the SSE endpoint, e.g. <code>http://example.com:8000/sse</code>.</li>
</ul>
<p>The MCP configuration file uses a JSON format with the following structure:</p>
<pre><code class="lang-json">// This example demonstrated an MCP server using the stdio format
// Cursor automatically runs this process for you
{
  "mcpServers": {
    "server-name": {
      "command": "npx",
      "args": ["-y", "mcp-server"],
      "env": {
        "API_KEY": "value"
      }
    }
  }
}

// This example demonstrated an MCP server using the SSE format
// The user should manually setup and run the server
// This could be networked, to allow others to access it too
{
  "mcpServers": {
    "server-name": {
      "url": "http://localhost:3000/sse",
      "env": {
        "API_KEY": "value"
      }
    }
  }
}
</code></pre>
<p>The Chat Agent will automatically use any MCP tools that are listed under <code>Available Tools</code> on the MCP settings page if it determines them to be relevant. To prompt tool usage intentionally, simply tell the agent to use the tool, referring to it either by name or by description. You can also enable or disable individual MCP tools from the settings page to control which tools are available to the Agent.</p>
<blockquote><p>MCP servers offer two main capabilities: tools and resources. Tools are available in Cursor today, and allow Cursor to execute the tools offered by an MCP server, and use the output in its further steps. However, resources are not yet supported in Cursor. We are hoping to add resource support in future releases.</p>
</blockquote>
<h2>Cline</h2>
<p>Cline is a VS Code extension that brings AI-powered coding assistance directly to your editor.</p>
<p>Plan &amp; Act modes represent Cline’s approach to structured AI development, emphasizing thoughtful planning before implementation. Plan mode is where you and Cline figure out what you’re trying to build and how you’ll build it. In this mode, Cline can read your entire codebase to understand the context, and won’t make any changes to your files. Once you’ve got a plan, you switch to Act mode. This mode allows Cline to execute against the agreed plan and make changes to your codebase.</p>
<p>If you’re new to Cline - for anything you want to do:</p>
<ul>
<li>write your prompt, select “plan”, run it.</li>
<li>once that’s done, assuming you don’t want it to change anything it planned, press “act”.</li>
</ul>
<blockquote><p>Cline doesn't index your codebase (Code doesn't work in chunks and moves fast). Instead, it begins by understanding the architecture. Using ASTs, Cline extracts a high-level map of your code – the classes, functions, methods, and their relationships. No index or embeddings. Just intelligent exploration, building context by following the natural structure of your code.</p>
</blockquote>
<h3>Context Window</h3>
<p>Context window determines how much information the model can “remember” and process at once during your conversation. This includes your conversation and the assistant’s response. Different models have different context window sizes.</p>
<p>Cline helps you manage this limitation with its Context Window Progress Bar, which shows:</p>
<ul>
<li>Input tokens (what you’ve sent to the model)</li>
<li>Output tokens (what the model has generated)</li>
<li>A visual representation of how much of your context window you’ve used</li>
<li>The total capacity for your chosen model</li>
</ul>
<h3>Cline rules</h3>
<p>You can create a rule by clicking the <code>+</code> button in the Rules tab. This will open a new file in your IDE which you can use to write your rule. Your rule will be stored in the <code>.clinerules</code> directory in your project (if it’s a Workspace Rule) or in the <code>Documents/Cline/Rules</code> directory (if it’s a Global Rule).</p>
<h3><code>@</code> Mentions</h3>
<p><code>@</code> mentions are one of Cline’s most powerful features, letting you seamlessly bring external context into your conversations. These mentions let you reference files, folders, problems, terminal output, git changes, and even web content directly in your conversations.</p>
<ol>
<li>When you send a message, Cline scans the text for <code>@</code> mention patterns using regular expressions.</li>
<li>For each detected mention, Cline determines the mention type, fetches the relevant content, and formats the content appropriately.</li>
<li>The original message is enhanced with structured data, and this enhanced message with all the embedded content is sent to the AI model.</li>
</ol>
<h3>Tools</h3>
<p>Cline has access to the following tools for various tasks:</p>
<ul>
<li>File Operations: <code>write_to_file</code>, <code>read_file</code>, <code>search_files</code>, <code>list_files</code></li>
<li>Terminal Operations: <code>execute_command</code>, <code>list_code_definition_names</code></li>
<li>MCP Tools: <code>use_mcp_tool</code>, <code>access_mcp_resource</code></li>
</ul>
<h2>Coding agent and agent mode in GitHub Copilot</h2>
<ul>
<li>Agent mode: a real‑time collaborator that sits in your editor, works with you, and edits files based on your needs.</li>
<li>Coding agent: an asynchronous teammate that lives in the cloud, takes on issues, and sends you fully tested pull requests while you do other things. <em>(Requires Copilot Pro+ or Copilot Enterprise)</em></li>
</ul>
<p><strong>Agent mode</strong> transforms Copilot Chat into an orchestrator of tools (<code>read_file</code>, <code>edit_file</code>, <code>run_in_terminal</code>, etc.). Give it a natural‑language goal—“add OAuth to our Flask app and write tests”—and it plans, edits files, runs the test suite, reads failures, fixes them, and loops until green. You watch the steps, intervene when you like, and keep all changes local.</p>
<p>While agent mode lives in the IDE, <strong>coding agent</strong> lives in your repos. Assign an issue to Copilot, and it spins up a secure cloud workspace (via GitHub Actions), figures out a plan, edits code on its own branch, runs your tests/linters, and opens a pull request tagging you for review. Check out <a href="https://code.visualstudio.com/docs/copilot/copilot-coding-agent">https://code.visualstudio.com/docs/copilot/copilot-coding-agent</a></p>
<p>Microsoft have released the GitHub Copilot Chat client for VS Code under an open source (MIT) license. So far this is just the extension that provides the chat component of Copilot. The agent instructions can be found in <a href="https://github.com/microsoft/vscode-copilot-chat/blob/main/src/extension/prompts/node/agent/agentInstructions.tsx">prompts/node/agent/agentInstructions.tsx</a>.</p>
<h3>Adding repository custom instructions</h3>
<p>Create a <code>.github/copilot-instructions.md</code> file in your repository's root directory and add natural language instructions in Markdown format. These instructions will guide Copilot's behavior across your project.</p>
<ul>
<li><a href="https://code.visualstudio.com/docs/copilot/copilot-customization">https://code.visualstudio.com/docs/copilot/copilot-customization</a></li>
<li><a href="https://github.com/github/awesome-copilot">https://github.com/github/awesome-copilot</a></li>
<li><a href="https://burkeholland.github.io/posts/beast-mode-3-1">https://burkeholland.github.io/posts/beast-mode-3-1</a></li>
</ul>
<h2>Gemini CLI</h2>
<p>Gemini CLI brings the capabilities of Gemini models to your terminal in an interactive Read-Eval-Print Loop (REPL) environment. Gemini CLI consists of a client-side application (<code>packages/cli</code>) that communicates with a local server (<code>packages/core</code>), which in turn manages requests to the Gemini API and its AI models. Gemini CLI also contains a variety of tools for tasks such as performing file system operations, running shells, and web fetching, which are managed by <code>packages/core</code>.</p>
<ul>
<li>Query and edit large codebases in and beyond Gemini's 1M token context window.</li>
<li>Generate new apps from PDFs or sketches, using Gemini's multimodal capabilities.</li>
<li>Automate operational tasks, like querying pull requests or handling complex rebases.</li>
<li>Use tools and MCP servers to connect new capabilities.</li>
<li>Ground your queries with the Google Search tool, built in to Gemini.</li>
</ul>
<pre><code class="lang-sh"># CLI Commands: https://github.com/google-gemini/gemini-cli/blob/main/docs/cli/commands.md

# Save and resume conversation history
/chat list
/chat save &lt;tag&gt;
/chat resume &lt;tag&gt;

# Replace the entire chat context with a summary. 
# This saves on tokens used for future tasks while 
# retaining a high level summary of what has happened.
/compress

# Display a list of tools that are currently available within Gemini CLI.
# https://github.com/google-gemini/gemini-cli/blob/main/docs/tools/index.md
/tools

# List MCP servers
# Configure the MCP server in `.gemini/settings.json` file
/mcp

# Manage the AI's instructional context
# (hierarchical memory loaded from GEMINI.md files).
/memory add &lt;text to remember&gt;
/memory show
</code></pre>
<p>Gemini CLI uses <code>settings.json</code> files for persistent configuration.</p>
<ul>
<li>User settings file at <code>~/.gemini/settings.json</code>. Applies to all Gemini CLI sessions for the current user.</li>
<li>Project settings file at <code>.gemini/settings.json</code> within your project's root directory.</li>
</ul>
<pre><code class="lang-json">{
  "mcpServers": {
    "context7": {
      "command": "npx",
      "args": ["-y", "@upstash/context7-mcp"]
    },
    "browsermcp": {
      "command": "npx",
      "args": ["@browsermcp/mcp@latest"]
    }
  }
}
</code></pre>
<blockquote><p>Tip: Always mention "use context7" at the end of your prompts to make sure the AI uses the Context7 server for the most current documentation and examples.</p>
</blockquote>
<p>Gemini CLI can be run in a non-interactive mode, which is useful for scripting and automation. In this mode, you pipe input to the CLI, it executes the command, and then it exits.</p>
<pre><code class="lang-sh">echo "What is fine tuning?" | gemini

gemini -p "What is fine tuning?"
</code></pre>
<p>The core system prompt lives in <a href="https://github.com/google-gemini/gemini-cli/blob/main/packages/core/src/core/prompts.ts">packages/core/src/core/prompts.ts</a> or read it <a href="https://gist.github.com/simonw/9e5f13665b3112cea00035df7da696c6">here</a>.</p>
