<h2><a href="https://github.com/kexizeroing/kexizeroing.github.io/blob/master/src/blog/start-to-use-cursor-and-copilot.md">仓库源文</a>，<a href="https://kexizeroing.github.io/start-to-use-cursor-and-copilot">站点原文</a></h2>
<h2>Get Started with Cursor</h2>
<p>Migrate VS Code settings:</p>
<ol>
<li><code>Cmd + Shift + P</code> and type Cursor Settings (or <code>Cmd + Shift + J</code> to open Cursor settings)</li>
<li>Navigate to General &gt; Account</li>
<li>Under “VS Code Import”, click the Import button</li>
</ol>
<p>This will transfer your Extensions, Themes, Settings, Keybindings. You can see all keyboard shortcuts by pressing <code>Cmd + R</code> then <code>Cmd + S</code>.</p>
<p>We made Activity Bar Orientation horizontal by default. If you prefer vertical:</p>
<ol>
<li><code>Cmd + Shift + P</code> -&gt; Preferences: Open Settings (UI)</li>
<li>Search for <code>workbench.activityBar.orientation</code> and set it to <code>vertical</code></li>
</ol>
<p>Start exploring Cursor’s AI-powered features:</p>
<ul>
<li>Tab: Press <code>Tab</code> for intelligent code completions</li>
<li>CMD-K: Use <code>Cmd + K</code> for inline code edits</li>
<li>Chat: Use <code>Cmd + I</code> to open the unified AI interface with Ask, Edit, and Agent modes
​
Cursor lets you input your own API keys for various LLM providers to send as many AI messages as you want at your own cost. To use your own API key, go to Cursor Settings &gt; Models and enter your API keys.</li>
</ul>
<p>To view your current usage, you can visit the dashboard at <a href="https://www.cursor.com/dashboard">cursor.com/dashboard</a></p>
<h3>Tab</h3>
<p>Cursor Tab is our native autocomplete feature. You can accept a suggestion by pressing <code>Tab</code>, or reject it by pressing <code>Esc</code>.</p>
<h3>Chat (Cmd + I)</h3>
<p>Chat (previously “Composer”) is Cursor’s AI assistant that lives in your sidebar, letting you interact with your codebase through natural language.</p>
<p>Sometimes you may want to revert to a previous state of your codebase. Cursor helps you with this by automatically creating checkpoints of your codebase at each request you make, as well every time the AI makes changes to your codebase. To revert to a previous state, you can click the “Restore Checkpoint” button that appears within the input box of a previous request.</p>
<p>Agent is the default and most autonomous mode in Cursor, designed to handle complex coding tasks with minimal guidance. It has all tools enabled to autonomously explore your codebase, read documentation, browse the web, edit files, and run terminal commands to complete tasks efficiently.</p>
<p>Ask is a “read-only” mode for the Chat made to ask questions, explore, and learn about a codebase. It is a built-in mode in Cursor that has search tools enabled by default.</p>
<p>Manual mode is designed for making targeted code modifications when you know exactly what changes are needed and where. To make use of Manual mode, you need to explicitly mention the files you want to edit using the <code>@</code> symbol. <em>e.g. “In @src/utils/helpers.ts and @src/components/UserProfile.tsx, rename the function <code>getUserData</code> to <code>fetchUserProfile</code> and update all call sites within these files.”</em></p>
<h3>Inline Edit (Cmd + K)</h3>
<p>We call the bar that appears when you press <code>Cmd + K</code> the “Prompt Bar”. It works similarly to the AI input box for chat, in which you can type normally, or use <code>@</code> symbols to reference other context.</p>
<p>If no code is selected when you press <code>Cmd + K</code>, Cursor will generate new code based on the prompt you type in the prompt bar. For in-place edits, you can simply select the code you want to edit and type into the prompt bar.</p>
<p>When your changes might affect multiple files or you need more advanced capabilities, use <code>Cmd + L</code> to send your selected code to the Agent. This seamlessly transitions your work to Chat mode.</p>
<h3>Context</h3>
<p>When a project is opened, each Cursor instance will initialize indexing for that workspace. After the initial indexing setup is complete, Cursor will automatically index any new files added to your workspace to keep your codebase context current. Behind the scenes, Cursor computes embeddings for each file in your codebase, and will use these to improve the accuracy of your codebase answers.</p>
<p>The status of your codebase indexing is under Cursor Settings &gt; Features &gt; Codebase Indexing.</p>
<p>You can control which directories and files Cursor can access by adding a <code>.cursorignore</code> file to your root directory. Cursor makes its best effort to block access to files listed in <code>.cursorignore</code> from codebase indexing, Tab, Chat, Cmd-K, and <code>@</code> symbol references.</p>
<p>In Cursors input boxes, you can use <code>@</code> symbols by typing <code>@</code>. A popup menu will appear with a list of suggestions, and it will automatically filter to only show the most relevant suggestions based on your input.</p>
<h3>Rules</h3>
<p>LLMs do not retain memory between completions. Rules solve this by providing persistent, reusable context at the prompt level. When a rule is applied, its contents are included at the start of the model context. Rules apply to both <code>Chat</code> and <code>Cmd-K</code>.</p>
<p>Project rules live in <code>.cursor/rules</code>. Each rule is stored as a file and version-controlled. Each rule file is written in MDC (<code>.mdc</code>), a lightweight format that supports metadata and content in a single file.</p>
<pre><code class="lang-mdc">---
description: xxx
globs: **/**
---

...content goes here...
</code></pre>
<p>You can use <code>Cmd + Shift + P</code> &gt; “New Cursor Rule” to create a rule quickly from inside Cursor. This will create a new rule file in the <code>.cursor/rules</code> directory. You can also generate rules directly in a conversation using the <code>/Generate Cursor Rules</code> command.</p>
<blockquote><p>The <code>.cursorrules</code> file in the root of your project is still supported, but will be deprecated. We recommend migrating to the Project Rules format for more control, flexibility, and visibility.</p>
</blockquote>
<p>You can organize rules by placing them in <code>.cursor/rules</code> directories throughout your project structure. For example:</p>
<pre><code>project/
  .cursor/rules/    # Project-wide rules
  backend/
    .cursor/rules/  # Backend-specific rules
  frontend/
    .cursor/rules/  # Frontend-specific rules
</code></pre>
<p>Nested rules automatically attached when files in their directory are referenced. This is particularly useful in monorepos or projects with distinct components that need their own specific guidance.</p>
<ul>
<li><a href="https://github.com/PatrickJS/awesome-cursorrules">https://github.com/PatrickJS/awesome-cursorrules</a></li>
<li><a href="https://cursorlist.com">https://cursorlist.com</a></li>
<li><a href="https://cursor.directory">https://cursor.directory</a></li>
</ul>
<h3>MCP</h3>
<p>Think of MCP as a plugin system for Cursor - it allows you to extend the Agent’s capabilities by connecting it to various data sources and tools through standardized interfaces.</p>
<p>Cursor supports two transport types for MCP servers:</p>
<ul>
<li>For stdio servers, the command should be a valid shell command that Cursor can run.</li>
<li>For SSE servers, the URL should be the URL of the SSE endpoint, e.g. <code>http://example.com:8000/sse</code>.</li>
</ul>
<p>The MCP configuration file uses a JSON format with the following structure:</p>
<pre><code class="lang-json">// This example demonstrated an MCP server using the stdio format
// Cursor automatically runs this process for you
{
  "mcpServers": {
    "server-name": {
      "command": "npx",
      "args": ["-y", "mcp-server"],
      "env": {
        "API_KEY": "value"
      }
    }
  }
}

// This example demonstrated an MCP server using the SSE format
// The user should manually setup and run the server
// This could be networked, to allow others to access it too
{
  "mcpServers": {
    "server-name": {
      "url": "http://localhost:3000/sse",
      "env": {
        "API_KEY": "value"
      }
    }
  }
}
</code></pre>
<p>The Chat Agent will automatically use any MCP tools that are listed under <code>Available Tools</code> on the MCP settings page if it determines them to be relevant. To prompt tool usage intentionally, simply tell the agent to use the tool, referring to it either by name or by description. You can also enable or disable individual MCP tools from the settings page to control which tools are available to the Agent.</p>
<blockquote><p>MCP servers offer two main capabilities: tools and resources. Tools are available in Cursor today, and allow Cursor to execute the tools offered by an MCP server, and use the output in its further steps. However, resources are not yet supported in Cursor. We are hoping to add resource support in future releases.</p>
</blockquote>
<h2>GitHub Copilot</h2>
<h3>Coding agent and agent mode</h3>
<ul>
<li>Agent mode: a real‑time collaborator that sits in your editor, works with you, and edits files based on your needs.</li>
<li>Coding agent: an asynchronous teammate that lives in the cloud, takes on issues, and sends you fully tested pull requests while you do other things. <em>(Requires Copilot Pro+ or Copilot Enterprise)</em></li>
</ul>
<p><strong>Agent mode</strong> transforms Copilot Chat into an orchestrator of tools (<code>read_file</code>, <code>edit_file</code>, <code>run_in_terminal</code>, etc.). Give it a natural‑language goal—“add OAuth to our Flask app and write tests”—and it plans, edits files, runs the test suite, reads failures, fixes them, and loops until green. You watch the steps, intervene when you like, and keep all changes local.</p>
<p>While agent mode lives in the IDE, <strong>coding agent</strong> lives in your repos. Assign an issue to Copilot, and it spins up a secure cloud workspace (via GitHub Actions), figures out a plan, edits code on its own branch, runs your tests/linters, and opens a pull request tagging you for review. Check out <a href="https://code.visualstudio.com/docs/copilot/copilot-coding-agent">https://code.visualstudio.com/docs/copilot/copilot-coding-agent</a></p>
<blockquote><p>Copilot coding agent starts working when you assign a GitHub Issue to Copilot, start a task from the <a href="https://github.blog/news-insights/product-news/agents-panel-launch-copilot-coding-agent-tasks-anywhere-on-github">agents panel</a>, or initiate a task from Copilot Chat in VS Code. From there, the agent opens a draft pull request, pushes commits as it works, and logs key steps along the way so you can track its progress in real time.</p>
</blockquote>
<p>[2025-07] Microsoft have released the GitHub Copilot Chat client for VS Code under an open source (MIT) license. So far this is just the extension that provides the chat component of Copilot. The agent instructions can be found in <a href="https://github.com/microsoft/vscode-copilot-chat/blob/main/src/extension/prompts/node/agent/agentInstructions.tsx">prompts/node/agent/agentInstructions.tsx</a>.</p>
<p>[2025-09] GitHub releases the GitHub Copilot CLI, a new entry that brings the power of Copilot directly to the command line. By simply running <code>copilot</code>, you enter an interactive session where you can prompt the agent, review its plans, and approve its actions in a conversational turn-based manner. It defaults to Claude Sonnet 4 but you can set <code>COPILOT_MODEL=gpt-5</code> to switch to GPT-5. It's billed against your existing GitHub Copilot account.</p>
<h3>Creating custom instructions</h3>
<p>Repository-wide custom instructions, which apply to all requests made in the context of a repository. These are specified in a <code>.github/copilot-instructions.md</code> file in your repository's root directory.</p>
<blockquote><p>Configure your repositories with <code>.github</code>: <a href="https://cassidoo.co/post/dot-github/">https://cassidoo.co/post/dot-github/</a></p>
</blockquote>
<p>Path-specific custom instructions, which apply to requests made in the context of files that match a specified path. These are specified in one or more <code>NAME.instructions.md</code> files within the <code>.github/instructions</code> directory in the repository. At the start of the file, create a frontmatter block containing the <code>applyTo</code> keyword. Use glob syntax to specify what files or directories the instructions apply to.</p>
<p>You can create one or more <code>AGENTS.md</code> files, stored anywhere within the repository. It can be found at the root of a repository or within subdirectories (e.g., <code>backend/AGENTS.md</code>, <code>frontend/AGENTS.md</code>). This allows for fine-grained control and specialized instructions for different parts of a project.</p>
<p>What happens when you send a prompt in Copilot Chat?</p>
<pre><code>System Prompt
(core identity and global rules, tool use instructions, output format instructions)
  ↓
User Prompt
(environment info, workspace info and project file structure)
  ↓
User Prompt
(current date/time, file you added to chat)
  ↓
User Request: "write a function that..."
</code></pre>
<h3>Agent Skills</h3>
<p>Agent Skills are a lightweight, open format for extending AI agent capabilities with specialized knowledge and workflows. At its core, a skill is a folder containing a <code>SKILL.md</code> file. This file includes metadata and instructions that tell an agent how to perform a specific task. More at <a href="https://agentskills.io/">https://agentskills.io/</a></p>
<p>You can create Agent Skills to teach Copilot how to perform specialized tasks in a specific, repeatable way. Agent Skills are folders containing instructions, scripts, and resources that Copilot automatically loads when relevant to your prompt. Skills support is coming to the stable version of VS Code in early January 2026.</p>
<p>You can write your own skills, or use skills shared by others, such as those in the <a href="https://github.com/anthropics/skills">anthropics/skills</a> repository. Check out <a href="https://docs.github.com/copilot/concepts/agents/about-agent-skills">https://docs.github.com/copilot/concepts/agents/about-agent-skills</a></p>
<blockquote><p>Skills and MCP</p>
<p>MCP is where capability lives. It's what allows an AI agent to actually do things instead of just talking about them. Skills live at a different layer. Skills are about process and knowledge. They're markdown files that encode how work should be done.</p>
<p>MCP gives agents abilities. Skills teach agents how to use those abilities well.</p>
</blockquote>
<h3>What are premium requests</h3>
<p>Each time you send a prompt in a chat window or trigger a response from Copilot, you’re making a request. Some Copilot features use more advanced processing power and count as premium requests. Copilot Chat uses one premium request per user prompt, multiplied by the model's rate. This includes ask, edit, agent, and plan modes in Copilot Chat in an IDE.</p>
<p>Different models have different premium request multipliers, which can affect how much of your monthly usage allowance is consumed. GPT-5 mini, GPT-4.1 and GPT-4o are the included models, and do not consume any premium requests if you are on a paid plan.</p>
<p>If you use Copilot Free, your plan comes with up to 2,000 inline suggestion requests and up to 50 premium requests per month. All chat interactions count as premium requests.</p>
<p>If you're on a paid plan, you get unlimited inline suggestions and unlimited chat interactions using the included models. Paid plans also receive a monthly allowance of premium requests (300 for Copilot Pro, 1000 for Copilot Enterprise).</p>
<ul>
<li><a href="https://docs.github.com/en/copilot/get-started/plans">https://docs.github.com/en/copilot/get-started/plans</a></li>
<li><a href="https://docs.github.com/en/copilot/concepts/billing/copilot-requests">https://docs.github.com/en/copilot/concepts/billing/copilot-requests</a></li>
</ul>
<h2>Gemini CLI</h2>
<p>Gemini CLI brings the capabilities of Gemini models to your terminal in an interactive Read-Eval-Print Loop (REPL) environment. Gemini CLI consists of a client-side application (<code>packages/cli</code>) that communicates with a local server (<code>packages/core</code>), which in turn manages requests to the Gemini API and its AI models. Gemini CLI also contains a variety of tools for tasks such as performing file system operations, running shells, and web fetching, which are managed by <code>packages/core</code>.</p>
<ul>
<li>Query and edit large codebases in and beyond Gemini's 1M token context window.</li>
<li>Generate new apps from PDFs or sketches, using Gemini's multimodal capabilities.</li>
<li>Automate operational tasks, like querying pull requests or handling complex rebases.</li>
<li>Use tools and MCP servers to connect new capabilities.</li>
<li>Ground your queries with the Google Search tool, built in to Gemini.</li>
</ul>
<pre><code class="lang-sh"># CLI Commands: https://github.com/google-gemini/gemini-cli/blob/main/docs/cli/commands.md

# Save and resume conversation history
/chat list
/chat save &lt;tag&gt;
/chat resume &lt;tag&gt;

# Replace the entire chat context with a summary.
# This saves on tokens used for future tasks while
# retaining a high level summary of what has happened.
/compress

# Display a list of tools that are currently available within Gemini CLI.
# https://github.com/google-gemini/gemini-cli/blob/main/docs/tools/index.md
/tools

# List MCP servers
# Configure the MCP server in `.gemini/settings.json` file
/mcp

# Manage the AI's instructional context
# (hierarchical memory loaded from GEMINI.md files).
/memory add &lt;text to remember&gt;
/memory show
</code></pre>
<p>Gemini CLI uses <code>settings.json</code> files for persistent configuration.</p>
<ul>
<li>User settings file at <code>~/.gemini/settings.json</code>. Applies to all Gemini CLI sessions for the current user.</li>
<li>Project settings file at <code>.gemini/settings.json</code> within your project's root directory.</li>
</ul>
<pre><code class="lang-json">{
  "mcpServers": {
    "context7": {
      "command": "npx",
      "args": ["-y", "@upstash/context7-mcp"]
    },
    "browsermcp": {
      "command": "npx",
      "args": ["@browsermcp/mcp@latest"]
    }
  }
}
</code></pre>
<blockquote><p>Tip: Always mention "use context7" at the end of your prompts to make sure the AI uses the Context7 server for the most current documentation and examples.</p>
</blockquote>
<p>Gemini CLI can be run in a non-interactive mode, which is useful for scripting and automation. In this mode, you pipe input to the CLI, it executes the command, and then it exits.</p>
<pre><code class="lang-sh">echo "What is fine tuning?" | gemini

gemini -p "What is fine tuning?"
</code></pre>
<p>The core system prompt lives in <a href="https://github.com/google-gemini/gemini-cli/blob/main/packages/core/src/core/prompts.ts">packages/core/src/core/prompts.ts</a> or read it <a href="https://gist.github.com/simonw/9e5f13665b3112cea00035df7da696c6">here</a>.</p>
