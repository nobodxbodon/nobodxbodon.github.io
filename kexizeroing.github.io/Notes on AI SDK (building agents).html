<h2><a href="https://github.com/kexizeroing/kexizeroing.github.io/blob/master/src/blog/notes-on-ai-sdk.md">仓库源文</a>，<a href="https://kexizeroing.github.io/notes-on-ai-sdk">站点原文</a></h2>
<p>AI SDK is like an ORM for LLMs. It provides a simple interface to interact with different LLM providers, making it easy to switch between them without changing your code. The first part of this post is my learning notes from the <a href="https://www.youtube.com/watch?v=kDlqpN1JyIw">AI Engineer workshop</a> tutorial by Nico Albanese.</p>
<h2>Generate Text</h2>
<p>Make your first LLM call.</p>
<pre><code class="lang-js">import { openai } from "@ai-sdk/openai";
import { generateText } from "ai";
import "dotenv/config";

const main = async () =&gt; {
  const result = await generateText({
    model: openai("gpt-4o-mini"),
    prompt: "Hello, world!",
  });
  console.log(result.text);
};

main();
</code></pre>
<p><code>generateText</code> can take either <code>prompt</code> or <code>messages</code> as input.</p>
<pre><code class="lang-js">const result = await generateText({
  model: openai("gpt-4o-mini"),
  messages: [
    { role: "user", content: "Hello, world!" },
  ],
});
</code></pre>
<p>Changing providers with the AI SDK is as simple as changing two lines of code. We can pick a model that has web search built in, like <code>perplexity</code> or <code>gemini</code>, and we can even see what sources were used to generate the text.</p>
<pre><code class="lang-js">import { google } from "@ai-sdk/google";
import { generateText } from "ai";
import "dotenv/config";

const main = async () =&gt; {
  const result = await generateText({
    model: google("gemini-1.5-flash", { useSearchGrounding: true }),
    prompt: "When is the AI Engineer summit in 2025?",
  });

  console.log(result.text);
  console.log(result.sources);
};

main();
</code></pre>
<h2>Stream Text</h2>
<pre><code class="lang-js">import { openai } from "@ai-sdk/openai";
import { streamText } from "ai";

const result = streamText({
  model: openai("gpt-4o"),
  prompt: "Invent a new holiday and describe its traditions.",
});

for await (const textPart of result.textStream) {
  process.stdout.write(textPart);
}
</code></pre>
<h2>Tools (or Function Calling)</h2>
<p>At the core, we give the model a prompt and also pass a list of tools that available. Each of these tools will be provided with a name, a description so the model knows when to use it, and any data it requires to run.</p>
<pre><code class="lang-js">import { openai } from "@ai-sdk/openai";
import { generateText, tool } from "ai";
import "dotenv/config";
import { z } from "zod";

const main = async () =&gt; {
  const result = await generateText({
    model: openai("gpt-4o"),
    prompt: "What's 10 + 5?",
    tools: {
      addNumbers: tool({
        description: "Add two numbers together",
        parameters: z.object({
          num1: z.number(),
          num2: z.number(),
        }),
        execute: async ({ num1, num2 }) =&gt; {
          return num1 + num2;
        },
      }),
    },
  });
  console.log(result.toolResults);
  // [
  //   {
  //     type: 'tool-result',
  //     toolCallId: '...',
  //     toolName: 'addNumbers',
  //     args: { num1: 10, num2: 5},
  //     result: 15,
  //   }
  // ]
};

main();
</code></pre>
<p>Now we only have the tool results and the model hasn't actually answered the question (<code>result.text</code> is empty). How can we get the model incorporate the tool results into a generated text answer?</p>
<p>When <code>maxSteps</code> is set to a number greater than 1 and the model generates a tool call, the AI SDK will trigger a new generation passing in the tool result until there are no further tool calls or the maximum number of tool steps is reached.</p>
<blockquote><p>If you just need the tool's call result, you can directly access it from <code>message.toolInvocations</code> (no need for <code>maxSteps</code>). It's when you need to feed the result of the tool invocation back to LLM for it to interpret and respond that's when you need <code>maxSteps</code>.</p>
</blockquote>
<pre><code class="lang-js">const main = async () =&gt; {
  const result = await generateText({
    model: openai("gpt-4o"),
    prompt: "What's 10 + 5?",
    maxSteps: 2,
    tools: {
      addNumbers: tool({
        description: "Add two numbers together",
        parameters: z.object({
          num1: z.number(),
          num2: z.number(),
        }),
        execute: async ({ num1, num2 }) =&gt; {
          return num1 + num2;
        },
      }),
    },
  });

  console.log(result.text); // 10 + 5 equals 15.
  console.log(JSON.stringify(result.steps, null, 2));
  // step 1: The model generates a tool call, and the tool is executed.
  // step 2: The tool result is sent to the model, and the model generates a response.
};
</code></pre>
<p>We can have multiple tools over multiple steps.</p>
<pre><code class="lang-js">const main = async () =&gt; {
  const result = await generateText({
    model: openai("gpt-4o"),
    prompt: "Get the weather in SF and NY, then add them together.",
    maxSteps: 3,
    tools: {
      addNumbers: tool({
        description: "Add two numbers together",
        parameters: z.object({
          num1: z.number(),
          num2: z.number(),
        }),
        execute: async ({ num1, num2 }) =&gt; {
          return num1 + num2;
        },
      }),
      getWeather: tool({
        description: "Get the current weather at a location",
        parameters: z.object({
          latitude: z.number(),
          longitude: z.number(),
          city: z.string(),
        }),
        execute: async ({ latitude, longitude, city }) =&gt; {
          const response = await fetch(
            `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&amp;longitude=${longitude}&amp;current=temperature_2m,weathercode,relativehumidity_2m&amp;timezone=auto`,
          );

          const weatherData = await response.json();
          return {
            temperature: weatherData.current.temperature_2m,
            weatherCode: weatherData.current.weathercode,
            humidity: weatherData.current.relativehumidity_2m,
            city,
          };
        },
      }),
    },
  });
  console.log(result.steps.length);
  console.log(result.text);
};

main();
</code></pre>
<p>You may ask we are not providing the <code>latitude</code> and <code>longitude</code>. It is the inference capablity we can use, so we can let the language model infer these parameters from the context of the conversation.</p>
<h2>Structured Output</h2>
<p>There are two ways to generate structured output with the AI SDK. One is using experimental output option with <code>generateText</code>, and the other is using <code>generateObject</code> function.</p>
<pre><code class="lang-js">const main = async () =&gt; {
  const result = await generateText({
    model: openai('gpt-4o'),
    prompt: 'Get the weather in SF and NY, then add them together.',
    maxSteps: 3,
    experimental_output: Output.object({
      schema: z.object({ sum: z.string() }),
    }),
    tools: {
      addNumbers: tool({...}),
      getWeather: tool({...}),
    },
  })

  console.log(result.experimental_output)
  // { sum: 27.5 }
}
</code></pre>
<pre><code class="lang-js">const main = async () =&gt; {
  const result = await generateObject({
    model: openai("gpt-4o-mini"),
    prompt: "Please come up with 3 definitions for AI agents.",
    schema: z.object({
      definitions: z.array(z.string()),
    }),
  });
  console.log(JSON.stringify(result.object, null, 2));
  // {
  //   "definitions": [
  //     "An AI agent is ...",
  //     "An AI agent is ...",
  //     "An AI agent is ..."
  //   ]
  // }
};

// Generate an array
const { object } = await generateObject({
  model: openai("gpt-4.1"),
  output: "array",
  schema: z.object({
    name: z.string(),
    class: z
      .string()
      .describe("Character class, e.g. warrior, mage, or thief."),
    description: z.string(),
  }),
  prompt: "Generate 3 hero descriptions for a fantasy role playing game.",
});

// Generate an enum
const { object } = await generateObject({
  model: openai("gpt-4.1"),
  output: "enum",
  enum: ["action", "comedy", "drama", "horror", "sci-fi"],
  prompt: "Classify the genre of this movie plot: "
    + "\"A group of astronauts travel through a wormhole in search of a "
    + "new habitable planet for humanity.\"",
});
</code></pre>
<h2>Deep Research</h2>
<p>The rough steps will be:</p>
<ol>
<li>Take the initial input</li>
<li>Generate search queries</li>
<li>Map through each query and<ul>
<li>Search the web for a relevant result</li>
<li>Analyze the result for learnings and follow-up questions</li>
<li>If depth &gt; 0, follow-up with a new query</li>
</ul>
</li>
</ol>
<p>Let's start by creating a function to generate search queries.</p>
<pre><code class="lang-js">const generateSearchQueries = async (query: string, n: number = 3) =&gt; {
  const {
    object: { queries },
  } = await generateObject({
    model: openai('gpt-4o'),
    prompt: `Generate ${n} search queries for the following query: ${query}`,
    schema: z.object({
      queries: z.array(z.string()).min(1).max(5),
    }),
  })
  return queries
}

const main = async () =&gt; {
  const prompt = 'What do you need to be a D1 shotput athlete?'
  const queries = await generateSearchQueries(prompt)
  // [
  //   'requirements to be a D1 shotput athlete',
  //   'training regimen for D1 shotput athletes',
  //   'qualifications for NCAA Division 1 shotput',
  // ]
}
</code></pre>
<p>Now we need to map these queries to web search results. We use <a href="https://exa.ai">Exa</a> for this.</p>
<pre><code class="lang-js">import Exa from 'exa-js'

const exa = new Exa(process.env.EXA_API_KEY)

const searchWeb = async (query: string) =&gt; {
  const { results } = await exa.searchAndContents(query, {
    numResults: 1,
    livecrawl: 'always', // not use cache
  })
  return results.map(
    (r) =&gt;({
      title: r.title,
      url: r.url,
      content: r.text,
    })
  )
}
</code></pre>
<p>Next thing is to give the model two tools, one to search the web, the other to evaluate the relevance of that tool call. This is the most complicated part of entire workflow, also the agentic part of workflow.</p>
<pre><code class="lang-js">const searchAndProcess = async (query: string) =&gt; {
  const pendingSearchResults: SearchResult[] = []
  const finalSearchResults: SearchResult[] = []
  await generateText({
    model: openai('gpt-4o'),
    prompt: `Search the web for information about ${query}`,
    system:
      'You are a researcher. For each query, search the web and then evaluate if the results are relevant and will help answer the following query',
    maxSteps: 5,
    tools: {
      searchWeb: tool({
        description: 'Search the web for information about a given query',
        parameters: z.object({
          query: z.string().min(1),
        }),
        async execute({ query }) {
          const results = await searchWeb(query)
          pendingSearchResults.push(...results)
          return results
        },
      }),
      evaluate: tool({
        description: 'Evaluate the search results',
        parameters: z.object({}),
        async execute() {
          const pendingResult = pendingSearchResults.pop()!
          const { object: evaluation } = await generateObject({
            model: openai('gpt-4o'),
            prompt: `Evaluate whether the search results are relevant and will help answer the following query: ${query}. If the page already exists in the existing results, mark it as irrelevant.

            &lt;search_results&gt;
            ${JSON.stringify(pendingResult)}
            &lt;/search_results&gt;
            `,
            output: 'enum',
            enum: ['relevant', 'irrelevant'],
          })
          if (evaluation === 'relevant') {
            finalSearchResults.push(pendingResult)
          }
          console.log('Found:', pendingResult.url)
          console.log('Evaluation:', evaluation)
          return evaluation === 'irrelevant'
            ? 'Search results are irrelevant. Please search again with a more specific query.'
            : 'Search results are relevant. End research for this query.'
        },
      }),
    },
  })
  return finalSearchResults
}

for (const query of queries) {
  console.log(`Searching the web for: ${query}`)
  const searchResults = await searchAndProcess(query)
}
</code></pre>
<p>The next step is to generate learnings and follow-up questions, and then add recursion to the <code>deepResearch</code> function.</p>
<pre><code class="lang-js">const generateLearnings = async (query: string, searchResult: SearchResult) =&gt; {
  const { object } = await generateObject({
    model: openai('gpt-4o'),
    prompt: `The user is researching "${query}". The following search result were deemed relevant.
    Generate a learning and a follow-up question from the following search result:

    &lt;search_result&gt;
    ${JSON.stringify(searchResult)}
    &lt;/search_result&gt;
    `,
    schema: z.object({
      learning: z.string(),
      followUpQuestions: z.array(z.string()),
    }),
  })
  return object
}
</code></pre>
<pre><code class="lang-js">const deepResearch = async (
  query: string,
  depth: number = 1,
  breadth: number = 3
) =&gt; {
  const queries = await generateSearchQueries(query)

  for (const query of queries) {
    console.log(`Searching the web for: ${query}`)
    const searchResults = await searchAndProcess(query)
    for (const searchResult of searchResults) {
      console.log(`Processing search result: ${searchResult.url}`)
      const learnings = await generateLearnings(query, searchResult)
      // call deepResearch recursively with decrementing depth and breadth
    }
  }
}
</code></pre>
<h2>Building agents with the AI SDK</h2>
<p>At its core, an agent can be defined with this simple equation: <code>agent = llm + memory + planning + tools + while loop</code></p>
<p>Below is the code taken from <a href="https://www.youtube.com/watch?v=V55AJYctIAY">Vercel Ship 2025 workshop</a> also by Nico Albanese, building a coding agent with the new AI SDK 5.</p>
<pre><code class="lang-js">import { generateText, stepCountIs, tool } from "ai";
import z from "zod/v4";
import fs from "fs";

export async function codingAgent(prompt: string) {
  const result = await generateText({
    // The AI Gateway is a proxy service that routes model requests to various AI providers. 
    // https://vercel.com/blog/ai-gateway
    model: "openai/gpt-4.1-mini",
    prompt,
    system:
      "You are a coding agent. You will be working with js/ts projects. Your responses must be concise. Always start by listing all the files in the current directory.",
    stopWhen: stepCountIs(10), // loop back up to 10 times until we generate text
    tools: {
      list_files: tool({
        description:
          "List files and directories at a given path. If no path is provided, lists files in the current directory.",
        inputSchema: z.object({
          path: z
            .string()
            .nullable()
            .describe(
              "Optional relative path to list files from. Defaults to current directory if not provided",
            ),
        }),
        execute: async ({ path: generatedPath }) =&gt; {
          if (generatedPath === ".git" || generatedPath === "node_modules") {
            return { error: "You cannot read the path: ", generatedPath };
          }
          const path = generatedPath?.trim() ? generatedPath : ".";
          try {
            console.log(`Listing files at '${path}'`);
            const output = fs.readdirSync(path, { recursive: false });
            return { path, output };
          } catch (e) {
            console.error(`Error listing files:`, e);
            return { error: e };
          }
        },
      }),
      read_file: tool({
        description:
          "Read the contents of a given relative file path. Use this when you want to see what's inside a file. Do not use this with directory names.",
        inputSchema: z.object({
          path: z
            .string()
            .describe("The relative path of a file in the working directory."),
        }),
        execute: async ({ path }) =&gt; {
          try {
            console.log(`Reading file at '${path}'`);
            const output = fs.readFileSync(path, "utf-8");
            return { path, output };
          } catch (error) {
            console.error(`Error reading file at ${path}:`, error.message);
            return { path, error: error.message };
          }
        },
      }),
      edit_file: tool({ 
        description:
          "Make edits to a text file or create a new file. Replaces 'old_str' with 'new_str' in the given file. 'old_str' and 'new_str' MUST be different from each other. If the file specified with path doesn't exist, it will be created.", 
          inputSchema: z.object({ 
            path: z.string().describe("The path to the file"), 
            old_str: z 
              .string() 
              .nullable() 
              .describe( 
                "Text to search for - must match exactly and must only have one match exactly", 
              ), 
            new_str: z.string().describe("Text to replace old_str with"), 
          }), 
          execute: async ({ path, old_str, new_str }) =&gt; { 
            try { 
              const fileExists = fs.existsSync(path); 
              if (fileExists &amp;&amp; old_str !== null) { 
                console.log(`Editing file '${path}'`); 
                const fileContents = fs.readFileSync(path, "utf-8"); 
                const newContents = fileContents.replace(old_str, new_str); 
                fs.writeFileSync(path, newContents); 
                return { path, success: true, action: "edit" }; 
              } else { 
                console.log(`Creating file '${path}'`); 
                fs.writeFileSync(path, new_str); 
                return { path, success: true, action: "create" }; 
              } 
            } catch (e) { 
              console.error(`Error editing file ${path}:`, e); 
              return { error: e, success: false }; 
            } 
          }, 
      }), 
    },
  });

  return {
    response: result.text,
  };
}
</code></pre>
<p>Note that if you omit <code>stopWhen</code>, the tool is called but you get an empty response. The reason is that the language model can generate either text or tool call. It doesn't do both at the same time. So in this case, the language model generates a tool call, we execute the tool and have a tool result. But our step is complete, and by default every request you make with the AI SDK will just be one single step. With the SDK, you can describe the stop conditions for when this loop should stop using <code>stopWhen</code> property.</p>
<p>Without the SDK, you have to manually wrap the entire call in a while loop, manage message history, and define some stop conditions.</p>
<h2>AI SDK UI</h2>
<p>AI SDK UI provides abstractions that simplify the complex tasks of managing chat streams and UI updates on the frontend, enabling you to develop dynamic AI-driven interfaces more efficiently. With three main hooks — <code>useChat</code>, <code>useCompletion</code>, and <code>useObject</code>.</p>
<ul>
<li>The <code>useChat</code> hook enables the streaming of chat messages from your AI provider. It manages the states for input, messages, status, error and more for you.</li>
<li>The <code>convertToModelMessages</code> function is used to transform an array of UI messages from the <code>useChat</code> hook into an array of <code>ModelMessage</code> objects, which are compatible with AI core functions like <code>streamText</code>.</li>
</ul>
<blockquote><p><a href="https://ai-sdk.dev/elements/overview">AI Elements</a> is a component library and custom registry built on top of shadcn/ui to help you build AI-native applications faster. It provides pre-built components like conversations, messages and more.</p>
</blockquote>
<pre><code class="lang-js">// app/api/chat/route.ts
import { streamText, convertToModelMessages, type UIMessage } from "ai";
import { openai } from "@ai-sdk/openai";

export async function POST(req: Request) {
  const { messages }: { messages: UIMessage[] } = await req.json();

  const result = streamText({
    model: openai("gpt-5-nano"),
    // messages: convertToModelMessages(messages),
    messages: [
      // Here to add system message or few-shot examples
      {
        role: "system",
        content: "You are a helpful coding assistant.",
      },
      ...convertToModelMessages(messages),
    ],
  });

  // Converts the result to a streamed response object with a UI message stream
  return result.toUIMessageStreamResponse();
}
</code></pre>
<pre><code class="lang-js">"use client";
import { useState } from "react";
import { useChat } from "@ai-sdk/react";

export default function ChatPage() {
  const [input, setInput] = useState("");
  // Defaults to DefaultChatTransport with `/api/chat` endpoint.
  // useChat({
  //   transport: new DefaultChatTransport({
  //     api: '/api/chat',
  //   }),
  // });
  const { messages, sendMessage, status, error, stop } = useChat();

  // `messages` is an array of UIMessage
  // [
  //   {
  //     id: "msg-1",
  //     role: "user",
  //     parts: [{ type: "text", text: "What is React?" }],
  //   },
  //   {
  //     id: "msg-2",
  //     role: "assistant",
  //     parts: [{ type: "text", text: "React is a JavaScript library..." }],
  //   },
  //   {
  //     id: "msg-3",
  //     role: "user",
  //     parts: [{ type: "text", text: "Can you give me an example?" }],
  //   }
  // ]

  const handleSubmit = (e: React.FormEvent&lt;HTMLFormElement&gt;) =&gt; {
    e.preventDefault();
    sendMessage({ text: input });
    setInput("");
  };

  return (
    &lt;div&gt;
      {error &amp;&amp; &lt;div&gt;{error.message}&lt;/div&gt;}
      {messages.map((message) =&gt; (
        &lt;div key={message.id}&gt;
          &lt;div&gt;{message.role === "user" ? "User: " : "AI: "}&lt;/div&gt;
          {message.parts.map((part, index) =&gt; {
            switch (part.type) {
              case "text":
                return (
                  &lt;div key={`${message.id}-${index}`}&gt;{part.text}&lt;/div&gt;
                );
              default:
                return null;
            }
          })}
        &lt;/div&gt;
      ))}
      {(status === "submitted" || status === "streaming") &amp;&amp; (
        &lt;div&gt;Loading...&lt;/div&gt;
      )}

      &lt;form onSubmit={handleSubmit}&gt;
        &lt;input value={input} onChange={(e) =&gt; setInput(e.target.value)} /&gt;
        {status === "submitted" || status === "streaming" ? (
          &lt;button onClick={stop}&gt;Stop&lt;/button&gt;
        ) : (
          &lt;button
            type="submit"
            disabled={status !== "ready"}
          &gt;
            Send
          &lt;/button&gt;
        )}
      &lt;/form&gt;
    &lt;/div&gt;
  );
}
</code></pre>
<p>For tool call UI, The <code>parts</code> array of assistant messages contains tool parts with typed names like <code>tool-getWeather</code>.</p>
<pre><code class="lang-js">// Check `type ToolUIPart` in ai/dist/index.d.ts
{
  message.parts.map((part, index) =&gt; {
    switch (part.type) {
      case "text":
        return (
          &lt;div key={`${message.id}-${index}`}&gt;
            {part.text}
          &lt;/div&gt;
        );
      // type: `tool-${NAME}`
      case "tool-getWeather":
        switch (part.state) {
          // [STATE: input-streaming] Receiving weather request...
          // {
          //   "city": "Beijing"
          // }
          case "input-streaming":
            return (
              &lt;div key={`${message.id}-getWeather-${index}`}&gt;
                Receiving weather request...
                &lt;pre&gt;{JSON.stringify(part.input, null, 2)}&lt;/pre&gt;
              &lt;/div&gt;
            );
          // [STATE: input-available] Getting weather for Beijing...
          case "input-available":
            return (
              &lt;div key={`${message.id}-getWeather-${index}`}&gt;
                Getting weather for {part.input.city}...
              &lt;/div&gt;
            );
          // [STATE: output-available] Weather: 80F and sunny
          case "output-available":
            return (
              &lt;div key={`${message.id}-getWeather-${index}`}&gt;
                &lt;div&gt;Weather: {part.output}&lt;/div&gt;
              &lt;/div&gt;
            );
          case "output-error":
            return (
              &lt;div key={`${message.id}-getWeather-${index}`}&gt;
                Error: {part.errorText}
              &lt;/div&gt;
            );
          default:
            return null;
        }
      default:
        return null;
    }
  });
}
</code></pre>
