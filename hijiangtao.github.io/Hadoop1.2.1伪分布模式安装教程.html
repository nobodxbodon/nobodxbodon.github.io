<h2><a href="https://github.com/hijiangtao/hijiangtao.github.io/blob/master/_posts/2014-02-17-hadoopsetup.md">仓库源文</a>，<a href="https://hijiangtao.github.io/2014/02/17/hadoopsetup">站点原文</a></h2>
<h2>一、硬件环境</h2>
<p><strong>Hadoop搭建系统环境</strong>：一台Linux ubuntu-13.04-desktop-i386系统，既做Namenode，又做Datanode。（ubuntu系统搭建在硬件虚拟机上）</p>
<p><strong>Hadoop安装目标版本</strong>：Hadoop1.2.1</p>
<p><strong>jdk安装版本</strong>：jdk-7u40-linux-i586</p>
<p><strong>Pig安装版本</strong>：pig-0.11.1</p>
<p><strong>硬件虚拟机搭设环境</strong>：IBM塔式服务器x3500M3 MT:7380</p>
<p><strong>eclipse安装版本</strong>：eclipse-standard-kepler-SR1-linux-gtk</p>
<hr/>
<h2>二、软件环境准备</h2>
<h3>2.1 Hadoop</h3>
<p>Hadoop Release 1.2.1(stable)版本，下载链接：<a href="http://mirror.nexcess.net/apache/hadoop/common/hadoop-1.2.1/">http://mirror.nexcess.net/apache/hadoop/common/hadoop-1.2.1/</a>，选择hadoop-1.2.1-bin.tar.gz文件下载。</p>
<h3>2.2 Java</h3>
<p>Java使用的jdk1.7版本，当然可以使用1.6的，下载链接：<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html">http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html</a>，选择Linux x86的 jdk-7u40-linux-i586.tar.gz版本下载（因为我的Linux机器是32位的）。如果Linux机器是64的就必须选择64位的下载，不同的机器必须要配置不同的jdk版本。</p>
<h3>2.3 Eclipse</h3>
<p>Eclipse选择Linux 32位下载：<a href="https://www.eclipse.org/downloads/">https://www.eclipse.org/downloads/</a></p>
<hr/>
<h2>三、安装步骤</h2>
<h3>3.1 添加一个专门为hadoop使用的用户</h3>
<ul>
<li>命令行输入：</li>
</ul>
<pre><code>sudo addgroup hadoop
sudo adduser -ingroup hadoop hadoop
</code></pre>
<ul>
<li>设置hadoop用户的sudo权限：</li>
</ul>
<pre><code>sudo vim /etc/sudoers
</code></pre>
<ul>
<li><p>在<code>root ALL=(ALL:ALL) ALL</code>下面加一行<code>hadoop ALL=(ALL:ALL) ALL</code></p>
</li>
<li><p>切换到hadoop用户：<code>su hadoop</code></p>
</li>
</ul>
<h3>3.2 创建目录并解压安装包</h3>
<ul>
<li>建立目录</li>
</ul>
<pre><code>sudo mkdir /home/hadoop/install
sudo mkdir /home/hadoop/software/hadoop /*该目录存储hadoop程序文件*/
sudo mkdir /home/hadoop/software/java /*该目录存储jdk程序文件。*/
sudo mkdir /home/hadoop/software/eclipse /*该目录存储eclipse程序文件。*/
</code></pre>
<ul>
<li>解压安装压缩包</li>
</ul>
<pre><code>sudo tar -xzvf '/home/master/下载/jdk-7u40-linux-i586.tar.gz' -C /home/hadoop/software/java/    
sudo tar -xzvf '/home/master/下载/hadoop-1.2.1-bin.tar.gz' -C /home/hadoop/software/hadoop/
</code></pre>
<h3>3.3 配置Hadoop</h3>
<ul>
<li>配置Java环境</li>
</ul>
<p>添加JAVA_HOME,CLASSPATH环境变量。使用<code>sudo vi /etc/profile</code>命令编辑profile文件，在文件末尾加上以下内容：</p>
<pre><code>HADOOP_INSTALL=/home/hadoop/software/hadoop/hadoop-1.2.1/
JAVA_HOME=/home/hadoop/software/java/jdk1.7.0_40
PATH=$JAVA_HOME/bin:$HADOOP_INSTALL/bin:$PATH
CLASSPATH=$JAVA_HOME/lib
export JAVA_HOME PATH CLASSPATH HADOOP_INSTALL
</code></pre>
<p>然后保存退出，使用<code>source /etc/profile</code>使刚刚的更改立即生效。</p>
<p>然后使用<code>java –version</code>命令，查看是否配置成功，如果成功会出现以下信息：</p>
<blockquote><p>java version “1.7.0_40″</p>
<p>Java(TM) SE Runtime Environment (build 1.7.0_40-b43)</p>
<p>Java HotSpot(TM) Client VM (build 24.0-b56, mixed mode)</p>
</blockquote>
<ul>
<li>配置SSH环境</li>
</ul>
<p>使用以下命令设置ssh无密码连接：</p>
<pre><code>ssh-keygen
cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys
ssh localhost
</code></pre>
<p>最后一行代码为测试使用。首次运行会提示是否继续，输入yes，回车，如果不要求输入密码，就表示成功了。</p>
<ul>
<li>配置hadoop环境</li>
</ul>
<p>通过<code>cd /home/hadoop/software/hadoop/hadoop-1.2.1/conf</code>进到conf这个目录，看到haddoop-env.sh,core-site.xml,mapred-site.xml,hdfs-site.xml这四个文件以及需要在完全分布模式配置的slaves和masters文件。</p>
<p>1.<strong>配置hadoop-env.sh</strong>：找到JAVA_HOME关键字所在的行，把前面的#号去掉，然后填写实际的JAVA_HOME地址：</p>
<pre><code>export  JAVA_HOME=/home/hadoop/software/java/jdk1.7.0_40
</code></pre>
<p>2.<strong>配置core-site.xml</strong>：用<code>vi core-site.xml</code>打开core-site.xml文件，然后在configuration标签中加入以下内容：</p>
<pre><code>&lt;property&gt;
&lt;name&gt;fs.default.name&lt;/name&gt;
&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
&lt;/property&gt;
&lt;!—fs.default.name：用来配置namenode,指定HDFS文件系统的URL，通过该URL我们可以访问文件系统的内容，也可以把localhost换成本机IP地址；如果是完全分布模式，则必须把localhost改为实际namenode机器的IP地址；如果不写端口，则使用默认端口8020。 –&gt;
&lt;property&gt;
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
&lt;value&gt;/home/hadoop/tmp/hadoop_tmp&lt;/value&gt;
&lt;/property&gt;
&lt;!– hadoop.tmp.dir：Hadoop的默认临时路径，这个最好配置，如果在新增节点或者其他情况下莫名其妙的DataNode启动不了，就删除此文件中的tmp目录即可。不过如果删除了NameNode机器的此目录，那么就需要重新执行NameNode格式化的命令。该目录必须预先手工创建。–&gt;
</code></pre>
<p>3.<strong>配置hdfs-site.xml</strong>：在configuration标签中加入以下内容：</p>
<pre><code>&lt;property&gt;
&lt;name&gt;dfs.data.dir&lt;/name&gt;
&lt;value&gt;/home/hadoop/appdata/hadoopdata&lt;/value&gt;
&lt;/property&gt;
&lt;!–配置HDFS存储目录,数据存放目录,用于datanode存放数据–&gt;
&lt;property&gt;
&lt;name&gt;dfs.name.dir&lt;/name&gt;
&lt;value&gt;/home/hadoop/appdata/hadoopname&lt;/value&gt;
&lt;/property&gt;
&lt;!—用来存储namenode的文件系统元数据，包括编辑日志和文件系统映像，如果更换地址的话，则需要重新使用hadoop namenode –format命令格式化namenode–&gt;
&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
&lt;!—用来设置文件系统冗余备份数量，因为只有一个节点，所有设置为1，系统默认数量为3–&gt;
</code></pre>
<p>注：之前在网上查到的资料显示有<em>所有不存在的目录都要预先创建</em>，但在实际操作中格式化过程经常出现错误，结果为namenode无法跑起来，多次经过查看错误日志发现是hadoopdata和hadoopname的配置存在，使得hadoop不允许格式化，所以当hadoop配置不成功时，建议查看一下日志，可以尝试将这两个文件夹删除再运行一次。</p>
<p><strong>hdfs-site.xml配置中两个文件夹不能提前建立的原因</strong>：感谢网友<strong>上海-草头</strong>的提醒，hadoop为了防止错误格式化已存在的集群，在这两个文件夹存在时，是不允许格式化的。</p>
<p>4.<strong>配置mapred-site.xml</strong>：在configuration标签中加入以下内容：</p>
<pre><code>&lt;property&gt;
&lt;name&gt;mapred.job.tracker&lt;/name&gt;
&lt;value&gt;localhost:9001&lt;/value&gt;
&lt;/property&gt;
&lt;!—该项配置用来配置jobtracker节点，localhost也可以换成本机的IP地址；真实分布模式下注意更改成实际jobtracker机器的IP地址–&gt;
</code></pre>
<hr/>
<h2>四、启动hadoop</h2>
<h3>4.1 测试hadoop配置是否成功</h3>
<p>通过以下命令，当我们看到hadoop的版本时则表明配置无误。</p>
<pre><code>hadoop version
</code></pre>
<h3>4.2 格式化namenode</h3>
<pre><code>cd /home/hadoop/software/hadoop/hadoop-1.2.1/bin
./hadoop namenode –format
</code></pre>
<h3>4.3 启动hadoop进程</h3>
<pre><code>cd /home/hadoop/software/hadoop/hadoop-1.2.1/bin
./start-all.sh
</code></pre>
<p>通过java的<code>jps</code>命令来查看进程是否启动成功，成功启动SecondaryNamenode，JobTracker，NameNode，DataNode，TraskTracker五个进程则OK。</p>
<p>如果有一个进程没有启动成功，就表示整个集群没有正常工作，进入<code>/home/hadoop/software/hadoop/hadoop-1.2.1/libexec/../logs/</code>目录下可以查看失败日记。</p>
<h3>4.4 从浏览器查看hadoop信息</h3>
<p><strong>查看jobtracker信息</strong>:</p>
<p>可以从本机或者其他机器的浏览器访问hadoop，输入如下网址：<a href="http://10.1.151.168:50030/jobtracker.jsp">http://10.1.151.168:50030/jobtracker.jsp</a>，其中10.1.151.168为我该机器的IP地址。</p>
<p><strong>查看namenode信息</strong>：</p>
<p><a href="http://10.1.151.168:50070/dfshealth.jsp">http://10.1.151.168:50070/dfshealth.jsp</a></p>
<p><strong>查看trasktracker信息</strong>：</p>
<p><a href="http://10.1.151.168:50060/tasktracker.jsp">http://10.1.151.168:50060/tasktracker.jsp</a></p>
<hr/>
<h2>错误笔记</h2>
<ul>
<li><strong>password:localhost:permission denied,please try again</strong></li>
</ul>
<p>碰到这种情况大都是没有给hadoop用户赋予sudo权限所致。所以打开你的<code>/etc/sudoers</code>加上<code>hadoop ALL=(ALL:ALL) ALL</code>吧。</p>
<ul>
<li><strong>Tasktracker无法正常启动</strong></li>
</ul>
<p>通过查找logs中tasktracker的错误日志发现其中有一个warn是相应目录下<code>temp/hadoop_tmp.mapred/local/</code>文件的权限被设置成<code>not writable</code>了。于是通过修改权限解决了上述的问题，命令如下：</p>
<pre><code>sudo chmod 777 /home/hadoop/temp/hadoop_tmp.mapred/local/
</code></pre>
<ul>
<li><strong>每次开机都需要把/etc/profile重新source一遍，不然就显示没装jdk</strong></li>
</ul>
<p>这个问题还是没有解决，因为还没找到原因所在。怎么办呢，算了，每次繁琐一点source一遍吧，暂时先这样了。</p>
<ul>
<li><strong>SafeMode: ON - HDFS unavailable</strong>，导致nodes显示为0，没有namenode启动。</li>
</ul>
<p>经过查询是hdfs-site.xml配置中的dfs.name.dir的value所在的目录出了问题，显示是：xxx is in an inconsistent state: storage directory does not exist or is not accessible.其中xxx代表那个目录，不断的重启与格式化总是不能解决这个问题，删不删除这个目录也都无济于事。是的，我疯了，你看到我疯狂的眼神了么？终于，突然想到了<code>chown</code>的作用，于是我执行了如下指令：</p>
<pre><code>sudo  chown -R hadoop:hadoop /home/hadoop/appdata/
</code></pre>
<p>重新格式化，然后start-all.sh，搞定了！总结为文件的权限问题。</p>
<hr/>
<h2>后记</h2>
<p>Hadoop1.2.1单机版搞定，老泪纵横啊！要是早一天我就可以向老师汇报我的胜利果实了！明天加油搞定全分布式集群配置！</p>
<p>感谢这段时间被我不断骚扰的中南学长和伍翀学长。</p>
<hr/>
<h2>声明</h2>
<p>本文已经成功投稿至36大数据网站，于2014-02-19发表。<a href="http://www.36dsj.com/archives/6088">链接地址</a></p>
