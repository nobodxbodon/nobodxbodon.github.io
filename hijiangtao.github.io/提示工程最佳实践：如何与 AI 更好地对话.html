<h2><a href="https://github.com/hijiangtao/hijiangtao.github.io/blob/master/_posts/2025-11-26-Prompt-Engineering-Best-Practices.md">仓库源文</a>，<a href="https://hijiangtao.github.io/2025/11/26/Prompt-Engineering-Best-Practices">站点原文</a></h2>
<p>Claude 最近新发了一篇关于提示工程最佳实践的文章，其中提到了诸多如何更好的写好提示词以利用 AI 帮助大家精准解决问题的思路，太长不看可以直接拿走这份思维导图。以下正文会详细给大家分享一下我认为文章还不错的很多精华部分。</p>
<p><img alt="" src="/Users/xuanwu/work/聚聚/中文博客集锦/源数据/博客聚合/hijiangtao.github.io/assets/in-post/2025-11-26-Prompt-Engineering-Best-Practices-MindMap.png"/></p>
<p>什么是提示工程？其本质是修改传递给大语言模型（LLM）的查询，核心是在实际请求前添加 “正确的信息”。提示工程的核心价值在于：</p>
<ul>
<li>提示工程是构建指令以从AI模型获得更优输出的技巧，包括表述查询、指定风格、提供上下文和引导模型行为等方面。</li>
<li>模糊指令与精心设计的提示差异显著：前者可能需要多次沟通澄清意图，后者可一次性达成目标。</li>
<li>提示工程是上下文工程的核心组成部分，与对话历史、附加文件和系统指令协同作用，共同优化AI输出结果。</li>
</ul>
<p>一个合适的学习路径应该是先掌握基础习惯，再逐步应用复杂项目的高级方法。</p>
<h2>一、核心基础技术</h2>
<h3>1. 指令明确清晰</h3>
<p>核心原则：直接告知模型期望的结果，不假设模型能推断需求，使用简洁无歧义的语言。</p>
<p><strong>最佳实践</strong></p>
<ul>
<li>以直接的动作动词开头（如“撰写”、“分析”、“生成”、“创建”）。</li>
<li>跳过开场白，直接切入请求核心。</li>
<li>明确输出应包含的内容，而非仅说明处理对象。</li>
<li>具体说明对质量和深度的期望。</li>
</ul>
<p><strong>示例对比</strong></p>
<pre><code>模糊表述：“创建一个分析仪表板”
明确表述：“创建一个分析仪表板，包含尽可能多的相关功能和交互，超越基础要求，实现功能完备的方案”
</code></pre>
<h3>2. 提供上下文与动机</h3>
<p>核心价值：解释需求背后的原因，帮助AI理解核心目标，生成更具针对性的响应（对能推理潜在目标的新型模型尤为有效）。</p>
<p><strong>适用场景</strong></p>
<ul>
<li>说明输出的用途或受众。</li>
<li>解释特定约束存在的原因。</li>
<li>描述输出的使用方式。</li>
<li>指明要解决的具体问题。</li>
</ul>
<p><strong>示例对比</strong></p>
<pre><code>效果较差：“绝不要使用项目符号”
效果更佳：“我偏好自然段落形式的响应而非项目符号，因为流畅的散文更易阅读且更具对话感，项目符号对我的轻松学习风格而言过于正式和列表化”
</code></pre>
<h3>3. 指令具体化</h3>
<p>核心要求：通过明确的指导方针和要求构建指令，具体程度越高，结果越优。</p>
<p><strong>需包含的关键要素</strong></p>
<ul>
<li>明确约束（字数、格式、时间线）。</li>
<li>相关上下文（受众、目标）。</li>
<li>期望的输出结构（表格、列表、段落）。</li>
<li>任何要求或限制（饮食需求、预算限制、技术约束）。</li>
</ul>
<p><strong>示例对比</strong></p>
<pre><code>模糊表述：“创建地中海饮食的膳食计划”
具体表述：“设计一份用于糖尿病前期管理的地中海饮食膳食计划，每日1800卡路里，重点关注低血糖指数食物，包含早餐、午餐、晚餐和一份加餐，并提供完整的营养成分分析”
</code></pre>
<h3>4. 使用示例（单样本/少样本提示）</h3>
<p>核心作用：通过示例直观展示期望的格式、语气或模式，比纯描述更易澄清复杂需求。</p>
<p><strong>注意事项</strong>：现代模型（如Claude 4.x）会密切关注示例细节，需确保示例与期望行为一致，避免传递不良模式。</p>
<p><strong>适用场景</strong></p>
<ul>
<li>期望格式难以用文字描述。</li>
<li>需要特定语气或风格。</li>
<li>任务涉及微妙模式或惯例。</li>
<li>简单指令无法产生一致结果。</li>
</ul>
<p><strong>实用技巧</strong></p>
<ul>
<li>先尝试1个示例（单样本），仅在输出不符合需求时添加更多示例（少样本）。</li>
</ul>
<p><strong>示例对比</strong></p>
<pre><code>无示例：“总结这篇文章”
带示例：“以下是我想要的总结风格示例：文章：[AI监管相关文章链接] 总结：欧盟通过全面的《人工智能法案》，针对高风险系统，核心条款包括透明度要求和人类监督规定，2026年生效。 现在按相同风格总结这篇文章：[新文章链接]”
</code></pre>
<h3>5. 允许AI表达不确定性</h3>
<p>核心目的：减少模型的幻觉（虚构信息），提高响应的可靠性。</p>
<p><strong>示例</strong></p>
<pre><code>分析这份财务数据并识别趋势，若数据不足以得出结论，请直接说明，不要猜测
</code></pre>
<h2>二、高级复杂场景技术</h2>
<h3>1. 预填充AI响应</h3>
<p>核心作用：提前启动AI的响应内容，引导输出的格式、语气或结构。</p>
<p><strong>适用场景</strong></p>
<ul>
<li>需要输出JSON、XML等结构化格式。</li>
<li>希望跳过对话开场白，直接获取核心内容。</li>
<li>需维持特定语气或角色。</li>
<li>要控制AI的响应开头方式。</li>
</ul>
<h3>2. 思维链提示（CoT）</h3>
<p>定义：要求AI在给出答案前进行分步推理，适用于复杂分析任务。</p>
<p><strong>适用场景</strong></p>
<ul>
<li>无“扩展思考”功能可用。</li>
<li>需要可审查的透明推理过程。</li>
<li>任务涉及多步分析。</li>
<li>需确保AI考虑特定因素。</li>
</ul>
<p><strong>三种常见实现方式</strong></p>
<ul>
<li>基础思维链：在指令中添加“分步思考”。示例：“为Care for Kids项目撰写个性化捐赠请求邮件，先分步思考再动笔”。</li>
<li>引导式思维链：指定具体推理阶段。示例：“撰写邮件前先思考：1. 根据捐赠者历史，哪些信息可能吸引他们；2. Care for Kids项目的哪些方面能引起共鸣；3. 基于分析撰写个性化邮件”。</li>
<li>结构化思维链：用标签分隔推理过程与最终答案。示例：“用<code>&lt;thinking&gt;</code>标签记录思考过程（分析吸引捐赠者的信息、项目相关亮点），用<code>&lt;email&gt;</code>标签呈现最终邮件”。</li>
</ul>
<p>注意事项：“扩展思考”与手动CoT可互补使用，复杂任务中结合使用效果更佳。</p>
<h3>3. 控制输出格式</h3>
<p>核心原则：通过正向引导、风格匹配和明确要求实现格式控制。</p>
<p><strong>三种有效方法</strong></p>
<ul>
<li>正向指令优先：不说“不要做什么”，而说“要做什么”。示例：不说“不要使用Markdown”，而说“响应应采用流畅的散文段落”。</li>
<li>提示风格与输出风格匹配：若希望输出少用Markdown，自身提示中也应减少Markdown使用。</li>
<li>明确格式偏好：详细说明格式要求。示例：“撰写报告时使用完整段落和标准分段，Markdown仅用于行内代码、代码块和简单标题；非必要不使用有序/无序列表，将内容自然融入句子中”。</li>
</ul>
<h3>4. 提示链</h3>
<p>定义：将复杂任务拆分为多个连续步骤，每个步骤用单独提示处理，前一步输出作为后一步输入。</p>
<p>核心优势：以增加延迟为代价，提高每个子任务的准确性，适合需要迭代优化或中间验证的场景。</p>
<p>适用场景：</p>
<ul>
<li>复杂请求需拆分步骤。</li>
<li>需要迭代优化输出。</li>
<li>多阶段分析任务。</li>
<li>中间验证能提升最终质量。</li>
<li>单条提示输出结果不一致。</li>
</ul>
<p>示例（研究总结）：</p>
<ol>
<li>第一条提示：“总结这篇医学论文，涵盖方法、发现和临床意义”。</li>
<li>第二条提示：“审查上述总结的准确性、清晰度和完整性，提供分级反馈”。</li>
<li>第三条提示：“根据以下反馈优化总结：[第二步的反馈内容]”。</li>
</ol>
<h2>三、技术整合使用提示</h2>
<h3>1. 尝试通过多技术组合达到目的</h3>
<pre><code>从这份季度报告中提取关键财务指标，以JSON格式呈现。该数据用于自动化处理，因此响应必须仅包含有效JSON，无开场白或解释。使用以下结构：{\"revenue\":\"带单位的值\",\"profit_margin\":\"百分比\",\"growth_rate\":\"百分比\"}。若报告中未明确说明某指标，用null表示，不要猜测。响应以左大括号开头：{
</code></pre>
<h3>2. 技术选择决策框架</h3>
<p><strong>基础判断步骤</strong></p>
<ul>
<li>需求是否清晰明确？若否，优先优化清晰度。</li>
<li>任务是否简单？是则仅使用核心技术（明确、具体、提供上下文）。</li>
<li>是否需要特定格式？使用示例、预填充或明确格式指令。</li>
<li>任务是否复杂？考虑拆分任务（提示链）。</li>
<li>是否需要推理？使用“扩展思考”（若可用）或思维链。</li>
</ul>
<p><strong>技术-需求匹配表</strong></p>
<table>
<thead><tr>
<th>需求场景</th>
<th>推荐技术</th>
</tr>
</thead>
<tbody>
<tr>
<td>特定输出格式</td>
<td>示例、预填充、明确格式指令</td>
</tr>
<tr>
<td>分步推理</td>
<td>扩展思考（Claude 4.x）、思维链</td>
</tr>
<tr>
<td>复杂多阶段任务</td>
<td>提示链</td>
</tr>
<tr>
<td>透明推理过程</td>
<td>带结构化输出的思维链</td>
</tr>
<tr>
<td>防止幻觉</td>
<td>允许AI说“不知道”</td>
</tr>
</tbody>
</table>
<h3>3. 常见问题故障排除</h3>
<table>
<thead><tr>
<th>问题现象</th>
<th>解决方案</th>
</tr>
</thead>
<tbody>
<tr>
<td>输出过于通用</td>
<td>增加特异性描述、提供示例、明确要求“超越基础内容”</td>
</tr>
<tr>
<td>输出偏离主题或未击中要点</td>
<td>更明确地说明核心目标，提供需求背后的上下文</td>
</tr>
<tr>
<td>输出格式不一致</td>
<td>添加示例（少样本）或使用预填充控制响应开头</td>
</tr>
<tr>
<td>任务复杂导致结果不可靠</td>
<td>拆分为多个提示（提示链），每个提示专注单一任务</td>
</tr>
<tr>
<td>AI添加不必要的开场白</td>
<td>使用预填充或明确要求“跳过开场白，直接给出答案”</td>
</tr>
<tr>
<td>AI虚构信息（幻觉）</td>
<td>明确允许AI在不确定时说明“不知道”</td>
</tr>
<tr>
<td>期望执行操作，AI却仅提供建议</td>
<td>明确动作指令（如“修改此函数”而非“你能建议修改吗？”）</td>
</tr>
</tbody>
</table>
<h3>4. 实用技巧</h3>
<ul>
<li>从简单提示开始，仅在需要时添加复杂技术。</li>
<li>每次添加技术后测试效果，确认是否真的提升输出质量。</li>
</ul>
<h2>四、常见错误与避坑指南</h2>
<ol>
<li>过度设计：更长、更复杂的提示不一定更好。</li>
<li>忽视基础：核心提示模糊不清时，高级技术无法弥补。</li>
<li>假设AI能“读心”：不明确的需求会导致AI误解，需具体化所有要求。</li>
<li>滥用技术：无需同时使用所有技术，仅选择解决特定问题的方法。</li>
<li>不迭代优化：首次提示极少完美，需测试并调整。</li>
<li>依赖过时技术：XML标签和过度角色提示对现代模型必要性低，优先使用明确指令。</li>
</ol>
<h2>五、最终建议</h2>
<ol>
<li>核心定位：提示工程本质是“沟通”，即用AI能清晰理解的语言表达意图。</li>
<li>学习路径：先熟练掌握核心技术，形成习惯后，仅在解决特定问题时添加高级技术。</li>
<li>优质提示的关键：并非最长或最复杂，而是能以最少的结构可靠达成目标。</li>
<li>与上下文工程的关系：提示工程是上下文工程的基础，每一个优质提示都是塑造AI行为的重要组成部分。</li>
</ol>
<h2>参考</h2>
<p>原文：<a href="https://claude.com/blog/best-practices-for-prompt-engineering">Best practices for prompt engineering</a></p>
