<h2><a href="https://github.com/hijiangtao/hijiangtao.github.io/blob/master/_posts/2014-02-18-hadoopclustersetup.md">仓库源文</a>，<a href="https://hijiangtao.github.io/2014/02/18/hadoopclustersetup">站点原文</a></h2>
<hr/>
<h2>date: 2014-02-18
layout: post
title: Hadoop1.2.1伪分布式升级全分布式集群改装笔记
thread: 38
categories: Tutorial
tags: [hadoop]
excerpt: Hadoop1.2.1伪分布式升级全分布式集群改装笔记</h2>
<h2>一、硬件环境</h2>
<p><strong>Hadoop搭建系统环境</strong>：三台完全一样的Linux ubuntu-13.04-desktop-i386系统，其中一个做Namenode和Datanode，另外两个做Datanode。（三个ubuntu系统均搭建在硬件虚拟机上）</p>
<p><strong>Hadoop安装目标版本</strong>：Hadoop1.2.1</p>
<p><strong>jdk安装版本</strong>：jdk-7u40-linux-i586</p>
<p><strong>Pig安装版本</strong>：pig-0.11.1</p>
<p><strong>硬件虚拟机搭设环境</strong>：IBM塔式服务器x3500M3 MT:7380</p>
<p><strong>eclipse安装版本</strong>：eclipse-standard-kepler-SR1-linux-gtk</p>
<hr/>
<h2>二、改装步骤</h2>
<h3>2.1 创建两个Datanode节点系统</h3>
<p>先用VMware vsphere client将一个ubuntu系统复制两份，系统分别命名为node1和node2。VMware vsphere client使用可以查看<a href="http://hijiangtao.github.io/2014/02/18/vmwaresetup">VMware vsphere client安装笔记</a>。</p>
<h3>2.2 修改Datanode系统中IP与主机名</h3>
<p>在打开每个系统的hostname文件，分别将名字改为node1和node2。</p>
<pre><code>sudo vim /etc/hostname
</code></pre>
<p>在每个系统的hosts文件中加入如下内容，以使联机运作时各节点能够被识别：</p>
<pre><code>10.1.151.168   master
10.1.151.178   node1
10.1.151.188   node2
</code></pre>
<h3>2.3 修改hadoop配置文件</h3>
<ul>
<li><strong>core-site.xml</strong></li>
</ul>
<p>将之前填写的localhost替换为master主机的实际IP，修改成果如下：</p>
<pre><code>&lt;property&gt;
&lt;name&gt;fs.default.name&lt;/name&gt;
&lt;value&gt;hdfs://10.1.151.168:9000&lt;/value&gt;
&lt;/propety&gt;
&lt;property&gt;
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
&lt;value&gt;/home/hadoop/tmp/hadoop_tmp&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<ul>
<li><strong>hdfs-site.xml</strong></li>
</ul>
<p>将节点数由1改为3：</p>
<pre><code>&lt;property&gt;
&lt;name&gt;dfs.data.dir&lt;/name&gt;
&lt;value&gt;/home/hadoop/appdata/hadoopdata&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;dfs.name.dir&lt;/name&gt;
&lt;value&gt;/home/hadoop/appdata/hadoopname&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;3&lt;/value&gt;
&lt;/proerty&gt;
</code></pre>
<ul>
<li><strong>mapred-site.xml</strong></li>
</ul>
<p>localhost修改如下：</p>
<pre><code>&lt;property&gt;
&lt;name&gt;mapred.job.tracker&lt;/name&gt;
&lt;value&gt;10.1.151.168:9001&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h3>2.4 namenode配置</h3>
<p>进入conf目录修改masters文件，填写集群master名如：</p>
<pre><code>master
</code></pre>
<p>保存退出然后打开slaves文件，添加作为slave的主机名，一行一个。</p>
<pre><code>master
node1
node2
</code></pre>
<hr/>
<h2>三、测试运行</h2>
<h3>3.1 格式化namenode</h3>
<pre><code>./hadoop namenode –format
</code></pre>
<h3>3.2 启动hadoop进程</h3>
<pre><code>./start-all.sh
</code></pre>
<p>检验方法和伪分布式相同，此处不再赘述。相关操作可以查看<a href="/2014/02/17/hadoopsetup">Hadoop1.2.1伪分布模式安装教程</a>。</p>
<hr/>
<h2>错误笔记</h2>
<ol>
<li>启动时发现莫名其妙的datanode没有启动，从logs日志中看到<code>Incompatible namespaceIDs in /home/hadoop/tmp/hadoop_tmp</code>，想起来这个文件夹是自己新建的，是不是伪分布式时在里面产生了垃圾？于是sudo rm -rf然后sudo mkdir重来了一次，想想不安全我再把其他的之前新建的文件夹全部重新按照这个方法操作了一次；最后-format然后./start-all.sh，搞定啦。Datanode、JobTracker、SecondaryNameNode、Jps、TaskTracker、NameNode全部启动。</li>
</ol>
