<h2><a href="https://github.com/wa008/wa008.github.io/blob/master/_posts/2022-05-31-Imagen.md">仓库源文</a>，<a href="https://informal.top/2022/05/31/Imagen">站点原文</a></h2>
<h1>背景</h1>
<p><a href="https://imagen.research.google/">Imagen</a> 是谷歌做的一个输入文本，自动生成对应图片的工具，突然看到 Imagen 的宣传，感觉 UGC 离现实生活越来越近了。
&lt;img src="/images/2022/05/457684880.png" width="500" alt=""&gt;</p>
<p>之前 GPT-3 生成的<a href="https://news.ycombinator.com/item?id=23893817">一篇文章</a>登顶 hacknews，引发一波热潮，但总觉得文本的 UGC 落地感觉还比较难，因为文本的理解成本高，审核成本高，但图像，是一个生成成本高、理解成本低的内容，特别是在视频横行的现在，现在生成成本可以让模型自动化来做了，落地应该也不远了。</p>
<p>机器自动生成文本或许不能完全替代摄影师，但应该还是会抢一些摄影社的饭碗，普通网民应该是没办法区分图片是自动生成的还是真人拍摄的，自动生成的效率一定比真人拍摄高，长久以往，网上大量的图片可能都是机器生成的了。
或许过几天就会有个 text-to-video 的论文出来。</p>
<h1>论文</h1>
<h3>文本表征</h3>
<p>通过语言模型将本文信息用 Embedding 表征，论文中用冻结的 T5 来做文本理解和表征。</p>
<p>作者发现提升 LM 的复杂度，相比提升扩散模型的复杂度能给 text-to-iamge 任务带来更多提升，说明该任务的瓶颈在于文本理解，也从一定角度说明文本理解还有一些提升空间。</p>
<h3>扩散模型</h3>
<p>利用扩散模型将 Embedding 生成为图像，进一步提升清晰度，输出结果。</p>
<p>扩散模型跟大名鼎鼎的 GAN 同属于生成网络，通过N步迭代，每一步以特定高斯分布采样噪音，添加到原始图像上，使其逐步变为 Embedding 隐变量，训练参数主要是生成噪音的正态分布的均值和方差。</p>
<p>原文还提出动态阈值的方法提升图片的真实度和清晰度；提出更简单高效的扩散模型结构 Efficient U-Net；在已有评测数据上达到 sota；提出新的评测数据。
出于安全和滥用的考虑，谷歌没有对外开源代码和模型工具。</p>
<h1>参考</h1>
<p><a href="https://www.zhaoyabo.com/?p=7675">https://www.zhaoyabo.com/?p=7675</a></p>
<p><a href="https://arxiv.org/abs/2205.11487">https://arxiv.org/abs/2205.11487</a></p>
